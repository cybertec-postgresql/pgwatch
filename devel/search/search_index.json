{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"index.html","title":"Hello world!","text":"<p>pgwatch is a flexible PostgreSQL-specific monitoring solution, offering a comprehensive view of database performance and health. It provides a user-friendly interface through Grafana dashboards, allowing users to easily inspect various metrics and trends.</p> <p>In the world of database management, monitoring plays a crucial role in ensuring stability, performance, and security. With a constant need to keep databases healthy and responsive, pgwatch answers three fundamental questions:</p> <p></p>"},{"location":"index.html#what","title":"What?","text":"<p>What sources to monitor?</p> <p>pgwatch is designed specifically for monitoring PostgreSQL databases and related infrastructure. It covers a wide range of components crucial for PostgreSQL ecosystems, including:</p> <ul> <li>PostgreSQL Databases: pgwatch monitors the core performance and health metrics of your PostgreSQL instances.</li> <li>Patroni Clusters: Monitor the health and performance of high-availability clusters members managed by Patroni.</li> <li>Connection Poolers (PgPool, PgBouncer): pgwatch provides insights into connection pooling with both PgPool and PgBouncer.</li> <li>Backup solutions: Track the performance and status of PgBackRest and WAL-G backups, ensuring that your backups are executed correctly.</li> </ul> <p>This extended monitoring capability allows you to gain a comprehensive view of not only your PostgreSQL databases but also the surrounding infrastructure that supports and enhances your database operations.</p>"},{"location":"index.html#how","title":"How?","text":"<p>What metrics are available for monitoring?</p> <p>pgwatch provides out-of-the-box support for almost all essential PostgreSQL metrics, including:</p> <ul> <li>Database health checks</li> <li>Query performance</li> <li>Index usage</li> <li>Disk I/O</li> <li>CPU and memory consumption</li> <li>Locks, waits, and more</li> </ul> <p>In addition to the standard metrics, pgwatch can be easily extended to monitor custom metrics based on your specific needs. The solution offers flexibility to fine-tune monitoring details and the aggressiveness of data collection.</p>"},{"location":"index.html#where","title":"Where?","text":"<p>Where are the measurements stored and where can users inspect the dashboards?</p> <ul> <li>pgwatch allows users to choose from a variety of storage backends aka sinks for storing monitoring data, such as JSON file, TimescaleDB, Prometheus, PostgreSQL, or a custom gRPC-based backend.</li> <li>The user interface for pgwatch is powered by Grafana dashboards, providing interactive and detailed visualization of the collected metrics. Users can easily view the performance and status of their databases in real-time, drill down into historical data, and configure custom dashboard views based on their preferences.</li> </ul> <p>For a detailed list of all features and capabilities, please refer to the Features page.</p>"},{"location":"concept/components.html","title":"Components","text":""},{"location":"concept/components.html#component-diagram","title":"Component diagram","text":"<p>The main development idea around pgwatch was to do the minimal work needed and not to reinvent the wheel - meaning that pgwatch is mostly just about gluing together already some proven pieces of software for metrics storage and using Grafana for dashboarding. So here is a listing of components that can be used to build up a monitoring setup around the pgwatch metrics collector. Note that most components are not mandatory and for tasks like metrics storage there are many components to choose from.</p> <p></p> <p>All components are loosely coupled, thus for non-pgwatch components (pgwatch components are only the metrics collector) you can decide to make use of an already existing installation of Postgres, Grafana or Prometheus and run additionally just the pgwatch collector.</p>"},{"location":"concept/components.html#the-metrics-gathering-daemon","title":"The metrics gathering daemon","text":"<p>The metrics collector, written in Go, is the only mandatory and most critical component of the whole solution. The main task of the pgwatch collector / daemon is pretty simple - reading the configuration and metric definitions, fetching the metrics from the configured databases using the configured connection info and finally storing the metric measurements to some other database, or just exposing them over a port for scraping in case of Prometheus mode.</p>"},{"location":"concept/components.html#configuration","title":"Configuration","text":"<p>The configuration says which databases, how often and with which metrics (SQL queries) are to be gathered. There are 2 options to store the configuration:</p> <ul> <li>A PostgreSQL database holding a simple schema with 5 tables.</li> <li>File based approach - YAML config file(s).</li> </ul>"},{"location":"concept/components.html#measurements-storage","title":"Measurements storage","text":"<p>Many options here so that one can for example go for maximum storage effectiveness or pick something where they already know the query language:</p>"},{"location":"concept/components.html#postgresql","title":"PostgreSQL","text":"<p>PostgreSQL is a world's most advanced Open Source RDBMS.</p> <p>Postgres storage is based on the JSONB datatype so minimally version 9.4+ is required, but for bigger setups where partitioning is a must, v11+ is needed. Any already existing Postgres database will do the trick, see the Bootstrapping the Metrics DB section for details.</p>"},{"location":"concept/components.html#timescaledb","title":"TimescaleDB","text":"<p>TimescaleDB is a time-series extension for PostgreSQL.</p> <p>Although technically a plain extension it's often mentioned as a separate database system as it brings custom data compression to the table, enabling huge disk savings over standard Postgres. Note that pgwatch does not use Timescales built-in retention management but a custom version.</p>"},{"location":"concept/components.html#prometheus","title":"Prometheus","text":"<p>Prometheus is a time series database and monitoring system.</p> <p>Though Prometheus is not a traditional database system, it's a good choice for monitoring Cloud-like environments as the monitoring targets don't need to know too much about how actual monitoring will be carried out later and also Prometheus has a nice fault-tolerant alerting system for enterprise needs. By default, Prometheus is not set up for long term metrics storage!</p>"},{"location":"concept/components.html#grpc","title":"gRPC","text":"<p>gRPC is a high-performance, open source RPC framework.</p> <p>It offers a way to push metrics to a custom storage backend  by implementing your own gRPC server based on pgwatch  protobuf definition. </p> <p>This is useful when none of the built-in storage options meet your needs.</p>"},{"location":"concept/components.html#json-files","title":"JSON files","text":"<p>Plain text files for testing / special use cases.</p>"},{"location":"concept/components.html#the-web-ui","title":"The Web UI","text":"<p>The second homegrown component of the pgwatch solution is an optional and relatively simple Web UI for administering details of the monitoring configuration like which databases should be monitored, with which metrics and intervals. Besides that there are some basic overview tables to analyze the gathered data and also possibilities to delete unneeded metric data (when removing a test host for example).</p>"},{"location":"concept/components.html#metrics-representation","title":"Metrics representation","text":"<p>Standard pgwatch setup uses Grafana for analyzing the gathered metrics data in a visual, point-and-click way. For that a rich set of predefined dashboards for Postgres is provided, that should cover the needs of most users - advanced users would mostly always want to customize some aspects though, so it's not meant as a one-size-fits-all solution. Also as metrics are stored in a DB, they can be visualized or processed in any other way.</p>"},{"location":"concept/installation_options.html","title":"Installation options","text":"<p>Besides freedom of choosing from a set of metric measurements storage options one can also choose how is the monitoring configuration (connect strings, metric sets and intervals) going to be stored.</p>"},{"location":"concept/installation_options.html#configuration-database-based-operation","title":"Configuration database based operation","text":"<p>This is the original central pull mode depicted on the architecture diagram. It requires a small schema to be rolled out on any Postgres database accessible to the metrics gathering daemon, which will hold the connect strings, metric definition SQLs and preset configurations and some other more minor attributes. For rollout details see the custom installation chapter.</p> <p>The default Docker demo image <code>cybertecpostgresql/pgwatch-demo</code> uses this approach.</p>"},{"location":"concept/installation_options.html#file-based-operation","title":"File based operation","text":"<p>One can deploy the gatherer daemon(s) decentralized with sources to be monitored defined in simple YAML files. In that case there is no need for the central Postgres configuration database. See the sample.sources.yaml config file for an example.</p> <p>Note</p> <p>In this mode you also may want, but not forced, to point out the path to metric definition YAML file when starting the gatherer. Also note that the configuration system supports multiple YAML files in a folder so that you could easily programmatically manage things via Ansible, for example, and you can also use environment variables inside YAML files.</p>"},{"location":"concept/kubernetes.html","title":"Kubernetes","text":"<p>A basic Helm chart templates for installing pgwatch to a Kubernetes cluster are available as a standalone repository.</p> <p>Notice</p> <p>Charts are not considered as a part of pgwatch and are not maintained by pgwatch developers.</p> <p>The corresponding setup can be found in repository, whereas installation is done via the following commands:</p> <pre><code>cd openshift_k8s\nhelm install -f chart-values.yml pgwatch ./helm-chart\n</code></pre> <p>Please have a look at <code>helm-chart/values.yaml</code> to get additional information of configurable options.</p>"},{"location":"concept/long_term_installations.html","title":"Long term installations","text":"<p>For long term pgwatch setups the main challenge is to keep the software up-to-date to guarantee stable operation and also to make sure that all DBs are under monitoring.</p>"},{"location":"concept/long_term_installations.html#keeping-inventory-in-sync","title":"Keeping inventory in sync","text":"<p>Adding new DBs to monitoring and removing those shut down, can become a problem if teams are big, databases are many, and it's done by hand (common for on-premise, non-orchestrated deployments). To combat that, the most typical approach would be to write some script or Cronjob that parses the company's internal inventory database, files or endpoints and translate changes to according CRUD operations on the pgwatch.source table directly.</p> <p>One could also use the REST API for that purpose.</p> <p>If pgwatch configuration is kept in YAML files, it should be also relatively easy to automate the maintenance as the configuration can be organized so that one file represent a single monitoring entry, i.e. the <code>--sources</code> and <code>--metrics</code> parameters can also refer to a folder of YAML files.</p>"},{"location":"concept/long_term_installations.html#updating-the-pgwatch-collector","title":"Updating the pgwatch collector","text":"<p>The pgwatch metrics gathering daemon is the core component of the solution alas the most critical one. So it's definitely recommended to update it at least once per year or minimally when some freshly released Postgres major version instances are added to monitoring. New Postgres versions don't necessary mean that something will break, but you'll be missing some newly added metrics, plus the occasional optimizations. See the upgrading chapter for details, but basically the process is very similar to initial installation as the collector doesn't have any state on its own - it's just one executable file.</p>"},{"location":"concept/long_term_installations.html#metrics-maintenance","title":"Metrics maintenance","text":"<p>Metric definition SQLs are regularly corrected as suggestions and improvements come in and also new ones are added to cover latest Postgres versions, so would make sense to refresh them 1-2x per year.</p> <p>If using built-in metrics, just installing newer pre-built RPM / DEB packages will do the trick automatically but for configuration database based setups you'd need to follow a simple process described here.</p>"},{"location":"concept/long_term_installations.html#dashboard-maintenance","title":"Dashboard maintenance","text":"<p>Same as with metrics, also the built-in Grafana dashboards are being actively updates, so would make sense to refresh them occasionally also. You could manually just re-import some dashboards of interest from JSON files in [/etc/pgwatch/grafana-dashboards] folder or from GitHub.</p> <p>Info</p> <p>Notable new dashboards are usually listed also in release notes and most dashboards also have a sample screenshots available.</p>"},{"location":"concept/long_term_installations.html#storage-monitoring","title":"Storage monitoring","text":"<p>In addition to all that you should at least initially periodically monitor the metric measurements databases size as it can grow quite a lot (especially when using Postgres for storage) when the monitored databases have hundreds of tables and indexes, and if a lot of unique SQLs are used and <code>pg_stat_statements</code> monitoring is enabled. If the storage grows too fast, one can increase the metric intervals (especially for \"table_stats\", \"index_stats\" and \"stat_statements\") or decrease the data retention periods via <code>--retention</code> param.</p>"},{"location":"concept/security.html","title":"Security aspects","text":""},{"location":"concept/security.html#general-security-information","title":"General security information","text":"<p>Security can be tightened for most pgwatch components quite granularly, but the default values for the Docker image don't focus on security though but rather on being quickly usable for ad-hoc performance troubleshooting, which is where the roots of pgwatch lie.</p> <p>Some points on security:</p> <ul> <li> <p>The administrative Web UI doesn't have by default any security.     Configurable via env. variables.</p> </li> <li> <p>Viewing Grafana dashboards by default doesn't require login.     Editing needs a password. Configurable via env. variables.</p> </li> <li> <p>Dashboards based on the \"stat_statements\" metric (Stat Statement     Overview / Top) expose actual queries.</p> <p>They should be \"mostly\" stripped of details though and replaced by placeholders by Postgres, but if no risks can be taken such dashboards (or at least according panels) should be deleted. Or as an alternative the <code>stat_statements_no_query_text</code> and <code>pg_stat_statements_calls</code> metrics could be used, which don't store query texts in the first place.</p> </li> <li> <p>Safe certificate connections to Postgres are supported. According     sslmode (verify-ca, verify-full) and cert file paths     need to be specified then in connection string on Web UI \"/dbs\" page     or in the YAML config.</p> </li> <li> <p>Note that although pgwatch can handle password security, in many     cases it's better to still use the standard LibPQ .pgpass file to     store passwords.</p> </li> </ul>"},{"location":"concept/security.html#launching-a-more-secure-docker-container","title":"Launching a more secure Docker container","text":"<p>Some common sense security is built into default Docker images for all components but not activated by default. A sample command to launch pgwatch with following security \"checkpoints\" enabled:</p> <ol> <li>HTTPS for both Grafana and the Web UI with self-signed certificates</li> <li>No anonymous viewing of graphs in Grafana</li> <li>Custom user / password for the Grafana \"admin\" account</li> <li>No anonymous access / editing over the admin Web UI</li> <li>No viewing of internal logs of components running inside Docker</li> <li> <p>Password encryption for connect strings stored in the Config DB</p> <pre><code>docker run --name pw3 -d --restart=unless-stopped \\\n  -p 3000:3000 -p 8080:8080 \\\n  -e PW_GRAFANASSL=1 -e PW_WEBSSL=1 \\\n  -e PW_GRAFANANOANONYMOUS=1 -e PW_GRAFANAUSER=myuser \\\n  -e PW_GRAFANAPASSWORD=mypass \\\n  -e PW_WEBNOANONYMOUS=1 -e PW_WEBNOCOMPONENTLOGS=1 \\\n  -e PW_WEBUSER=myuser -e PW_WEBPASSWORD=mypass \\\n  -e PW_AES_GCM_KEYPHRASE=qwerty \\\n  cybertec/pgwatch\n</code></pre> </li> </ol> <p>For custom installs it's up to the user though. A hint - Docker launcher files can also be inspected to see which config parameters are being touched.</p>"},{"location":"concept/web_ui.html","title":"The Admin Web UI","text":"<p>For easy configuration management (adding databases to monitoring, adding metrics) there is a Web application bundled.</p> <p>Besides managing the metrics gathering configurations, the two other useful features for the Web UI would be the possibility to look at the logs.</p> <p>Default port: 8080</p> <p>Sample screenshot of the Web UI:</p> <p></p>"},{"location":"concept/web_ui.html#web-ui-security","title":"Web UI security","text":"<p>By default, the Web UI is not secured - anyone can view and modify the monitoring configuration. If some security is needed though it can be enabled:</p> <ul> <li> <p>HTTPS</p> </li> <li> <p>Password protection is controlled by <code>--web-user</code>, <code>--web-password</code> command-line parameters or     <code>PW_WEBUSER</code>, <code>PW_WEBPASSWORD</code> environmental variables.</p> </li> </ul> <p>Note</p> <p>It's better to use standard LibPQ .pgpass files so there's no requirement to store any passwords in pgwatch config database or YAML config file.</p> <p>For security sensitive environments make sure to always deploy password protection together with SSL, as it uses a standard cookie based techniques vulnerable to snooping / MITM attacks.</p>"},{"location":"developer/CODE_OF_CONDUCT.html","title":"Citizen Code of Conduct","text":""},{"location":"developer/CODE_OF_CONDUCT.html#1-purpose","title":"1. Purpose","text":"<p>A primary goal of pgwatch is to be inclusive to the largest number of contributors, with the most varied and diverse backgrounds possible. As such, we are committed to providing a friendly, safe and welcoming environment for all, regardless of gender, sexual orientation, ability, ethnicity, socioeconomic status, and religion (or lack thereof).</p> <p>This code of conduct outlines our expectations for all those who participate in our community, as well as the consequences for unacceptable behavior.</p> <p>We invite all those who participate in pgwatch to help us create safe and positive experiences for everyone.</p>"},{"location":"developer/CODE_OF_CONDUCT.html#2-open-sourceculturetech-citizenship","title":"2. Open [Source/Culture/Tech] Citizenship","text":"<p>A supplemental goal of this Code of Conduct is to increase open [source/culture/tech] citizenship by encouraging participants to recognize and strengthen the relationships between our actions and their effects on our community.</p> <p>Communities mirror the societies in which they exist and positive action is essential to counteract the many forms of inequality and abuses of power that exist in society.</p> <p>If you see someone who is making an extra effort to ensure our community is welcoming, friendly, and encourages all participants to contribute to the fullest extent, we want to know.</p>"},{"location":"developer/CODE_OF_CONDUCT.html#3-expected-behavior","title":"3. Expected Behavior","text":"<p>The following behaviors are expected and requested of all community members:</p> <ul> <li>Participate in an authentic and active way. In doing so, you contribute to the health and longevity of this community.</li> <li>Exercise consideration and respect in your speech and actions.</li> <li>Attempt collaboration before conflict.</li> <li>Refrain from demeaning, discriminatory, or harassing behavior and speech.</li> <li>Be mindful of your surroundings and of your fellow participants. Alert community leaders if you notice a dangerous situation, someone in distress, or violations of this Code of Conduct, even if they seem inconsequential.</li> <li>Remember that community event venues may be shared with members of the public; please be respectful to all patrons of these locations.</li> </ul>"},{"location":"developer/CODE_OF_CONDUCT.html#4-unacceptable-behavior","title":"4. Unacceptable Behavior","text":"<p>The following behaviors are considered harassment and are unacceptable within our community:</p> <ul> <li>Violence, threats of violence or violent language directed against another person.</li> <li>Sexist, racist, homophobic, transphobic, ableist or otherwise discriminatory jokes and language.</li> <li>Posting or displaying sexually explicit or violent material.</li> <li>Posting or threatening to post other people's personally identifying information (\"doxing\").</li> <li>Personal insults, particularly those related to gender, sexual orientation, race, religion, or disability.</li> <li>Inappropriate photography or recording.</li> <li>Inappropriate physical contact. You should have someone's consent before touching them.</li> <li>Unwelcome sexual attention. This includes, sexualized comments or jokes; inappropriate touching, groping, and unwelcomed sexual advances.</li> <li>Deliberate intimidation, stalking or following (online or in person).</li> <li>Advocating for, or encouraging, any of the above behavior.</li> <li>Sustained disruption of community events, including talks and presentations.</li> </ul>"},{"location":"developer/CODE_OF_CONDUCT.html#5-weapons-policy","title":"5. Weapons Policy","text":"<p>No weapons will be allowed at pgwatch events, community spaces, or in other spaces covered by the scope of this Code of Conduct. Weapons include but are not limited to guns, explosives (including fireworks), and large knives such as those used for hunting or display, as well as any other item used for the purpose of causing injury or harm to others. Anyone seen in possession of one of these items will be asked to leave immediately, and will only be allowed to return without the weapon. Community members are further expected to comply with all state and local laws on this matter.</p>"},{"location":"developer/CODE_OF_CONDUCT.html#6-consequences-of-unacceptable-behavior","title":"6. Consequences of Unacceptable Behavior","text":"<p>Unacceptable behavior from any community member, including sponsors and those with decision-making authority, will not be tolerated.</p> <p>Anyone asked to stop unacceptable behavior is expected to comply immediately.</p> <p>If a community member engages in unacceptable behavior, the community organizers may take any action they deem appropriate, up to and including a temporary ban or permanent expulsion from the community without warning (and without refund in the case of a paid event).</p>"},{"location":"developer/CODE_OF_CONDUCT.html#7-reporting-guidelines","title":"7. Reporting Guidelines","text":"<p>If you are subject to or witness unacceptable behavior, or have any other concerns, please notify a community organizer as soon as possible. Pavlo Golub.</p> <p>Additionally, community organizers are available to help community members engage with local law enforcement or to otherwise help those experiencing unacceptable behavior feel safe. In the context of in-person events, organizers will also provide escorts as desired by the person experiencing distress.</p>"},{"location":"developer/CODE_OF_CONDUCT.html#8-addressing-grievances","title":"8. Addressing Grievances","text":"<p>If you feel you have been falsely or unfairly accused of violating this Code of Conduct, you should notify cybertec-postgresql with a concise description of your grievance. Your grievance will be handled in accordance with our existing governing policies. </p>"},{"location":"developer/CODE_OF_CONDUCT.html#9-scope","title":"9. Scope","text":"<p>We expect all community participants (contributors, paid or otherwise; sponsors; and other guests) to abide by this Code of Conduct in all community venues--online and in-person--as well as in all one-on-one communications pertaining to community business.</p> <p>This code of conduct and its related procedures also applies to unacceptable behavior occurring outside the scope of community activities when such behavior has the potential to adversely affect the safety and well-being of community members.</p>"},{"location":"developer/CODE_OF_CONDUCT.html#10-contact-info","title":"10. Contact info","text":"<p>Pavlo Golub Cybertec</p>"},{"location":"developer/CODE_OF_CONDUCT.html#11-license-and-attribution","title":"11. License and attribution","text":"<p>The Citizen Code of Conduct is distributed by Stumptown Syndicate under a Creative Commons Attribution-ShareAlike license. </p> <p>Portions of text derived from the Django Code of Conduct and the Geek Feminism Anti-Harassment Policy.</p> <p>Revision 2.3. Posted 6 March 2017.</p> <p>Revision 2.2. Posted 4 February 2016.</p> <p>Revision 2.1. Posted 23 June 2014.</p> <p>Revision 2.0, adopted by the Stumptown Syndicate board on 10 January 2013. Posted 17 March 2013.</p>"},{"location":"developer/LICENSE.html","title":"License","text":"<p>BSD 3-Clause License</p> <p>Copyright (c) 2022, CYBERTEC PostgreSQL International GmbH All rights reserved.</p> <p>Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:</p> <ul> <li> <p>Redistributions of source code must retain the above copyright notice, this   list of conditions and the following disclaimer.</p> </li> <li> <p>Redistributions in binary form must reproduce the above copyright notice,   this list of conditions and the following disclaimer in the documentation   and/or other materials provided with the distribution.</p> </li> <li> <p>Neither the name of the copyright holder nor the names of its   contributors may be used to endorse or promote products derived from   this software without specific prior written permission.</p> </li> </ul> <p>THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.</p>"},{"location":"developer/contributing.html","title":"Contributing to PGWatch","text":"<p>Thank you for considering contributing to PGWatch! Here are some guidelines to help you get started.</p>"},{"location":"developer/contributing.html#code-of-conduct","title":"Code of Conduct","text":"<p>Please read and follow our Code of Conduct.</p>"},{"location":"developer/contributing.html#communication-channels","title":"Communication Channels","text":"<p>The main communication channel for the project is the  GitHub repository.  Feel free to open issues and participate in discussions there.</p>"},{"location":"developer/contributing.html#setting-up-the-development-environment","title":"Setting Up the Development Environment","text":"<p>To set up the development environment, please refer to the instructions in the  README.md file. We use Docker Compose to simplify the setup process.</p>"},{"location":"developer/contributing.html#how-to-report-bugs","title":"How to Report Bugs","text":"<p>If you encounter any bugs, please report them by opening an issue in the  GitHub repository issues section.  Provide as much detail as possible to help us understand and resolve the issue.</p>"},{"location":"developer/contributing.html#how-to-request-features","title":"How to Request Features","text":"<p>If you have a feature request, please start a discussion in the  GitHub repository discussions section.  We value your feedback and ideas!</p>"},{"location":"developer/contributing.html#submitting-changes","title":"Submitting Changes","text":"<p>Before submitting any changes, please discuss them in the  GitHub repository discussions section.  This helps ensure that your contribution aligns with the project goals and prevents duplicate efforts.</p> <p>When you are ready to submit your changes, create a pull request. Make sure your pull request:</p> <ul> <li>Follows the Go Style Guide</li> <li>Includes tests for any new functionality or bug fixes</li> </ul>"},{"location":"developer/contributing.html#coding-standards","title":"Coding Standards","text":"<p>We follow the Go Style Guide.  Please ensure your code adheres to these guidelines.</p>"},{"location":"developer/contributing.html#testing","title":"Testing","text":"<p>We require tests for all changes. Please use the standard Go testing facilities.  Ensure that all tests pass before submitting your pull request.</p>"},{"location":"developer/contributing.html#documentation","title":"Documentation","text":"<p>Documentation for the project resides in the same repository. If you make changes  that require documentation updates, please include those changes in your pull request.</p>"},{"location":"developer/contributing.html#contributor-license-agreement-cla","title":"Contributor License Agreement (CLA)","text":"<p>We do not require contributors to sign a Contributor License Agreement (CLA).  By submitting a pull request, you agree that your contributions are submitted  under the same license as the project.</p> <p>We appreciate your contributions and efforts to improve PGWatch. If you have any questions,  feel free to reach out through the GitHub repository.</p> <p>Thank you!</p>"},{"location":"gallery/dashboards.html","title":"Dashboards","text":"<p>Dashboards are a collection of visualizations that are displayed in a single page. They are useful for monitoring and analyzing data.</p> <p>Health Check </p> <p>Global Health </p> <p>Biggest Tables Treemap </p> <p>Checkpointer, Background Writer, I/O statistics </p> <p>Indexes Overview </p> <p>Database Overview With Time Lag Comparison </p> <p>Database Overview for Developers (Unprivileged) </p> <p>Global Databases Overview </p> <p>Change Events </p> <p>PostgreSQL Versions Overview </p> <p>Recommendations </p> <p>Replication Lag </p> <p>Server Log Events </p> <p>Realtime Execution Plans </p> <p>Stat Activity Realtime </p> <p>Stat Statements SQL Search </p> <p>Stat Statements Top Visual </p> <p>Stat Statements Top </p> <p>System Statistics </p> <p>Tables Top </p>"},{"location":"gallery/webui.html","title":"Web User Interface","text":"<p>The Web User Interface (WebUI) allows you to interact with the pgwatch and control monitored sources, metrics and presets definitions, and view and logs.</p> <p>Sources </p> <p>Metrics </p> <p>Presets </p> <p>Logs  </p>"},{"location":"howto/config_db_bootstrap.html","title":"Bootstrapping the Configuration Database","text":""},{"location":"howto/config_db_bootstrap.html#choosing-a-database","title":"Choosing a Database","text":"<p>pgwatch supports any database that supports the PostgreSQL wire protocol. This includes:</p> <ul> <li>PostgreSQL</li> <li>TimescaleDB</li> <li>CitusDB</li> <li>CockroachDB</li> <li>many more</li> </ul> <p>We will use PostgreSQL in this guide. But the steps are similar for other databases. It's up to you to choose the database that best fits your needs and set it up accordingly.</p>"},{"location":"howto/config_db_bootstrap.html#creating-the-database","title":"Creating the Database","text":"<p>First, we need to create a database for storing the configuration. We will use the <code>psql</code> command-line tool to create the database. You can also use a GUI tool like pgAdmin to create the database.</p> <p>Let's assume we want to create a database named <code>pgwatch</code> on a completely fresh PostgreSQL installation. It is wise to use a special role for the configuration database, so we will create a role named <code>pgwatch</code> and assign it to the <code>pgwatch</code> database.</p> <pre><code>$ psql -U postgres -h localhost -p 5432 -d postgres\npsql (17.2)\n\npostgres=# CREATE ROLE pgwatch WITH LOGIN PASSWORD 'pgwatchadmin';\nCREATE ROLE\n\npostgres=# CREATE DATABASE pgwatch OWNER pgwatch;\nCREATE DATABASE\n</code></pre> <p>That's it! We have created a database named <code>pgwatch</code> with the owner <code>pgwatch</code>. Now we can proceed to the next step.</p>"},{"location":"howto/config_db_bootstrap.html#init-optional","title":"Init (optional)","text":"<p>pgwatch will automatically create the necessary tables and indexes in the database when it starts. But in case you want to create the schema as a separate step, you can use the <code>config init</code> command. The only thing you need is to provide the connection string to the database.</p> <pre><code>pgwatch --sources=postgresql://pgwatch:pgwatchadmin@localhost/pgwatch config init\n</code></pre> <p>Or you can use the <code>config init</code> command with the <code>--metrics</code> flag, since metrics and sources share the same database.</p> <pre><code>pgwatch --metrics=postgresql://pgwatch:pgwatchadmin@localhost/pgwatch config init\n</code></pre>"},{"location":"howto/config_db_bootstrap.html#usage","title":"Usage","text":"<p>You can now configure pgwatch to use the <code>pgwatch</code> database as the configuration database for storing monitored sources, metric deinitions and presets.</p> <pre><code>$ pgwatch --sources=postgresql://pgwatch:pgwatchadmin@localhost/pgwatch --sink=postgresql://pgwatch@10.0.0.42/measurements\n...\n[INFO] [metrics:75] [presets:17] [sources:2] sources and metrics refreshed\n...\n</code></pre> <p>Info</p> <p>Even though configuration database can hold both sources and metrics definitions, you are free to use any combination of configurations. For example, you can use a database for metrics and YAML file for sources, or vice versa.</p> <p>That's it! You have successfully bootstrapped the configuration database for pgwatch.</p> <p>If now you want to see the tables created by pgwatch in the configuration database, you can connect to the database using the <code>psql</code> command-line tool and list the tables.</p> <pre><code>$ psql postgresql://pgwatch:pgwatchadmin@localhost/pgwatch\npsql (17.2)\n\npgwatch=# \\dt pgwatch.*\n           List of relations\n Schema  |   Name    | Type  |  Owner\n---------+-----------+-------+---------\n pgwatch | metric    | table | pgwatch\n pgwatch | migration | table | pgwatch\n pgwatch | preset    | table | pgwatch\n pgwatch | source    | table | pgwatch\n(4 rows)\n</code></pre> <p>You may examine these tables to understand how pgwatch stores metrics and presets definitions, as well as what sources and how to monitor in the database.</p>"},{"location":"howto/dashboarding_alerting.html","title":"Dashboarding and alerting","text":""},{"location":"howto/dashboarding_alerting.html#grafana-intro","title":"Grafana intro","text":"<p>To display the gathered and stored metrics the pgwatch project has decided to rely heavily on the popular Grafana dashboarding solution. This means only though that it's installed in the default Docker images and there's a set of predefined dashboards available to cover most of the metrics gathered via the Preset Configs.</p> <p>This does not mean though that Grafana is in any way tightly coupled with project's other components - quite the opposite actually, one can use any other means / tools to use the metrics data gathered by the pgwatch daemon.</p> <p>Currently, there are around 30 preset dashboards available for PostgreSQL data sources. Due to that nowadays, if metric gathering volumes are not a problem, we recommend using Postgres storage for most users.</p> <p>Note though that most users will probably want to always adjust the built-in dashboards slightly (colors, roundings, etc.), so that they should be taken only as examples to quickly get started. Also note that in case of changes it's not recommended to change the built-in ones, but use the Save as features - this will allow later to easily update all the dashboards en masse per script, without losing any custom user changes.</p> <p>Links:</p> <ul> <li> <p>Built-in dashboards for PostgreSQL (TimescaleDB) storage</p> </li> <li> <p>Screenshots of pgwatch default dashboards</p> </li> <li> <p>The online Demo site</p> </li> </ul>"},{"location":"howto/dashboarding_alerting.html#alerting","title":"Alerting","text":"<p>Alerting is very conveniently also supported by Grafana in a simple point-and-click style - see here for the official documentation. In general all more popular notification services are supported, and it's pretty much the easiest way to quickly start with PostgreSQL alerting on a smaller scale. For enterprise usage with hundreds of instances it's might get too \"clicky\" though and there are also some limitations - currently you can set alerts only on Graph panels and there must be no variables used in the query so you cannot use most of the pre-created pgwatch graphs, but need to create your own.</p> <p>Nevertheless, alerting via Grafana is s a good option for lighter use cases and there's also a preset dashboard template named \"Alert Template\" from the pgwatch project to give you some ideas on what to alert on.</p> <p>Note though that alerting is always a bit of a complex topic - it requires good understanding of PostgreSQL operational metrics and also business criticality background infos, so we don't want to be too opinionated here, and it's up to the users to implement.</p>"},{"location":"howto/metrics_db_bootstrap.html","title":"Bootstrapping the Measurements Database (Sink)","text":""},{"location":"howto/metrics_db_bootstrap.html#choosing-a-database","title":"Choosing a Database","text":"<p>pgwatch supports multiple databases for storing metrics measurements. The following databases are supported:</p> <ul> <li>PostgreSQL</li> <li>TimescaleDB</li> <li>CitusDB</li> <li>CockroachDB</li> <li>any other database that supports the PostgreSQL wire protocol</li> </ul> <p>We will use PostgreSQL in this guide. But the steps are similar for other databases. It's up to you to choose the database that best fits your needs and set it up accordingly.</p>"},{"location":"howto/metrics_db_bootstrap.html#creating-the-database","title":"Creating the Database","text":"<p>First, we need to create a database for storing the metrics measurements. We will use the <code>psql</code> command-line tool to create the database. You can also use a GUI tool like pgAdmin to create the database.</p> <p>Let's assume we want to create a database named <code>measurements</code> on a completely fresh PostgreSQL installation. It is wise to use a special role for the metrics database, so we will create a role named <code>pgwatch</code> and assign it to the <code>measurements</code> database.</p> <pre><code>$ psql -U postgres -h 10.0.0.42 -p 5432 -d postgres\npsql (17.2)\n\npostgres=# CREATE ROLE pgwatch WITH LOGIN PASSWORD 'pgwatchadmin';\nCREATE ROLE\n\npostgres=# CREATE DATABASE measurements OWNER pgwatch;\nCREATE DATABASE\n</code></pre> <p>That's it! We have created a database named <code>measurements</code> with the owner <code>pgwatch</code>. Now we can proceed to the next step.</p>"},{"location":"howto/metrics_db_bootstrap.html#usage","title":"Usage","text":"<p>pgwatch will automatically create the necessary tables and indexes in the database when it starts. You don't need to create any tables or indexes manually.</p> <p>You can now configure pgwatch to use the <code>measurements</code> database as the sink for storing metrics measurements.</p> <pre><code>$ pgwatch --sources=/etc/sources.yaml --sink=postgresql://pgwatch@10.0.0.42/measurements\n[INFO] [sink:postgresql://pgwatch@10.0.0.42/measurements] Initialising measurements database...\n[INFO] [sink:postgresql://pgwatch@10.0.0.42/measurements] Measurements sink activated\n...\n</code></pre> <p>That's it! You have successfully bootstrapped the metrics measurements database for pgwatch. You can now start collecting metrics from your sources and storing them in the database.</p> <p>If now you want to see the tables created by pgwatch in the <code>measurements</code> database, you can connect to the database using the <code>psql</code> command-line tool and list the tables.</p> <pre><code>$ psql -U pgwatch -h 10.0.0.42 -p 5432 -d measurements\npsql (17.2)\n\nmeasurements=&gt; \\dn\n     List of schemas\n     Name      |  Owner\n---------------+---------\n admin         | pgwatch\n subpartitions | pgwatch\n(3 rows)\n</code></pre> <p>You can see that pgwatch has created the <code>admin</code> and <code>subpartitions</code> schemas in the <code>measurements</code> database. These schemas contain the tables and indexes used by pgwatch to store metrics measurements. You may examine these schemas to understand how pgwatch stores metrics measurements in the database.</p> <p>Tip</p> <p>You can also add <code>--log-level=debug</code> command-line parameter to see every SQL query executed by pgwatch. This can be useful for debugging purposes. But remember that this will log a lot of information, so it is wise to use it with empty sources this time, meaning there are no database to monitor yet.</p>"},{"location":"howto/migrate_v2_to_v3.html","title":"Migrating from v2 to v3","text":""},{"location":"howto/migrate_v2_to_v3.html#introduction","title":"Introduction","text":"<p>This guide will help you migrate from pgwatch2 to pgwatch v3. The migration process is straightforward and should not take long. Depending on your setup, you may need to migrate the configuration database or the configuration YAML files. Feel free to skip the steps that do not apply to your setup.</p> <p>Note</p> <p>Here and in the following examples under <code>pgwatch</code> name we understand v3 related binary, database, and user. If we refer to v2 related binary, database, or user, we will use <code>pgwatch2</code> name.</p>"},{"location":"howto/migrate_v2_to_v3.html#migrate-the-configuration-database","title":"Migrate the Configuration Database","text":"<p>Warning</p> <p>Before migrating, please, make a backup of your configuration database!</p> <p>Assuming you have a local PostgreSQL database named <code>pgwatch2</code> and a user named <code>pgwatch2</code> with the password <code>pgwatch2admin</code>, you can migrate the configuration database to pgwatch3 by following these steps:</p> <ol> <li> <p>Connect as superuser to the PostgreSQL instance and rename the <code>pgwatch2</code> role and database to <code>pgwatch</code>:</p> <pre><code>$ psql -U postgres -h localhost -p 5432 -d postgres\npsql (17.2)\n\npostgres=# ALTER ROLE pgwatch2 RENAME TO pgwatch;\nALTER ROLE\n\npostgres=# ALTER ROLE pgwatch WITH PASSWORD 'pgwatchadmin';\nALTER ROLE\n\npostgres=# ALTER DATABASE pgwatch2 RENAME TO pgwatch;\nALTER DATABASE\n</code></pre> </li> <li> <p>Use the <code>config init</code> command to create the necessary v3 tables and indexes in the <code>pgwatch</code> database:</p> <pre><code>pgwatch --sources=postgresql://pgwatch:pgwatchadmin@localhost/pgwatch config init\n</code></pre> </li> </ol>"},{"location":"howto/migrate_v2_to_v3.html#migrate-the-monitored-sources","title":"Migrate the monitored sources","text":"<p>To migrate the monitored sources execute the following query:</p> <pre><code>insert into pgwatch.source\nselect md_unique_name as name,\n    format('postgresql://%s:%s@%s:%s/%s', md_user, md_password, md_hostname, md_port, md_dbname) as connstr,\n    md_is_superuser as is_superuser,\n    md_preset_config_name as preset_config,\n    md_config as config,\n    md_is_enabled as is_enabled,\n    md_last_modified_on as last_modified_on,\n    md_dbtype as dbtype,\n    md_include_pattern as include_pattern,\n    md_exclude_pattern as exclude_pattern,\n    md_custom_tags as custom_tags,\n    md_group as \"group\",\n    md_host_config as host_config,\n    md_only_if_master as only_if_master,\n    md_preset_config_name_standby as preset_config_standby,\n    md_config_standby as config_standby\nfrom pgwatch2.monitored_db;\n</code></pre>"},{"location":"howto/migrate_v2_to_v3.html#migrate-the-metrics-and-presets","title":"Migrate the metrics and presets","text":"<p>Note</p> <p>You may skip this step if you have not created custom metrics or presets. All built-in metrics and presets are already included in pgwatch3.</p> <p>Exucute the following queries to migrate the metrics and presets:</p> <pre><code>insert into pgwatch.preset\nselect \n    pc_name as name, \n    pc_description as description, \n    pc_config as metrics \nfrom pgwatch2.preset_config\non conflict do nothing;\n</code></pre>"},{"location":"howto/migrate_v2_to_v3.html#migrate-the-configuration-yaml-files","title":"Migrate the Configuration YAML Files","text":"<p>To Be Done</p>"},{"location":"howto/sizing_recommendations.html","title":"Sizing recommendations","text":"<ul> <li> <p>Min 1GB of RAM is required for a Docker setup using Postgres to     store metrics.</p> <p>The gatherer alone needs typically less than 50 MB if the metric  measurements are stored online. Memory consumption will increase a lot when the metrics store is offline though, as then metrics are cached in RAM in ring buffer style up to a limit of 10k data points (for all databases) and then memory consumption is dependent on how \"wide\" are the metrics gathered.</p> </li> <li> <p>Storage requirements vary a lot and are hard to predict.</p> <p>10GB of disk space should be enough though for monitoring a single DB with \"exhaustive\" preset for 1 month with Postgres storage. 2 weeks is also the default metrics retention policy for Postgres running in Docker (configurable). Depending on the amount of schema objects - tables, indexes, stored procedures and especially on number of unique SQLs, it could be also much more. If disk size reduction is wanted for PostgreSQL storage then best would be to use the TimescaleDB extension - it has built-in compression and disk footprint is x5 time less than vanilla Postgres, while retaining full SQL support.</p> </li> <li> <p>A low-spec (1 vCPU, 2 GB RAM) cloud machine can easily monitor 100     DBs in \"exhaustive\" settings (i.e. almost all metrics are     monitored in 1-2min intervals) without breaking a sweat (\\&lt;20%     load).</p> </li> <li> <p>A single Postgres node should handle thousands of requests per     second.</p> </li> <li> <p>When high metrics write latency is problematic (e.g. using a DBaaS     across the Atlantic) then increasing the default maximum batching flush     delay of 950ms usually gives good results.     Relevant params: <code>--batching-delay / PW_BATCHING_DELAY</code>.</p> </li> <li> <p>Note that when monitoring a very large number of databases, it's     possible to \"shard\" / distribute them between many metric     collection instances running on different hosts, via the <code>group</code>     attribute. This requires that some hosts have been assigned a     non-default group identifier, which is just a text field exactly     for this sharding purpose.     Relevant params: <code>--group / PW_GROUP</code>.</p> </li> </ul>"},{"location":"howto/using_managed_services.html","title":"Monitoring managed cloud databases","text":"<p>Although all cloud service providers offer some kind of built-in instrumentation and graphs, they're mostly rather conservative in this are not to consume extra server resources and not to overflow and confuse beginners with too much information. So for advanced troubleshooting it might make sense to gather some additional metrics on your own, especially given that you can also easily add custom business metrics to pgwatch using plain SQL, for example to track the amount of incoming sales orders. Also with pgwatch / Grafana you have more freedom on the visual representation side and access to around 30 prebuilt dashboards and a lot of freedom creating custom alerting rules.</p> <p>The common denominator for all managed cloud services is that they remove / disallow dangerous or potentially dangerous functionalities like file system access and untrusted PL-languages like Python - so you'll lose a small amount of metrics and \"helper functions\" compared to a standard on-site setup described in the <code>previous chapter &lt;preparing_databases&gt;</code>. This also means that you will get some errors displayed on some preset dashboards like \"DB overview\" and thus will be better off using a dashboard called \"DB overview Unprivileged\" tailored specially for such a use case.</p> <p>pgwatch has been tested to work with the following managed database services:</p>"},{"location":"howto/using_managed_services.html#google-cloud-sql-for-postgresql","title":"Google Cloud SQL for PostgreSQL","text":"<ul> <li>No Python / OS helpers possible. OS metrics can be integrated in     Grafana though using the     Stackdriver     data source.</li> <li><code>pg_monitor</code> system role available.</li> <li>pgwatch default preset name: <code>gce</code>.</li> <li>Documentation: https://cloud.google.com/sql/docs/postgres</li> </ul> <p>To get most out pgwatch on GCE you need some additional clicks in the GUI / Cloud Console \"Flags\" section to enable some common PostgreSQL monitoring parameters like <code>track_io_timing</code> and <code>track_functions</code>.</p>"},{"location":"howto/using_managed_services.html#amazon-rds-for-postgresql","title":"Amazon RDS for PostgreSQL","text":"<ul> <li> <p>No Python / OS helpers possible. OS metrics can be integrated in     Grafana though using the     CloudWatch     data source</p> </li> <li> <p><code>pg_monitor</code> system role available.</p> </li> <li> <p>pgwatch default preset names: <code>rds</code>, <code>aurora</code></p> </li> <li> <p>Documentation:</p> <p>https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/CHAP_PostgreSQL.html https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/Aurora.AuroraPostgreSQL.html</p> </li> </ul> <p>Note that the AWS Aurora PostgreSQL-compatible engine is missing some additional metrics compared to normal RDS.</p>"},{"location":"howto/using_managed_services.html#azure-database-for-postgresql","title":"Azure Database for PostgreSQL","text":"<ul> <li>No Python / OS helpers possible. OS metrics can be integrated in     Grafana though using the Azure     Monitor     data source</li> <li><code>pg_monitor</code> system role available.</li> <li>pgwatch default preset name: <code>azure</code></li> <li>Documentation: https://docs.microsoft.com/en-us/azure/postgresql/</li> </ul> <p>Surprisingly on Azure some file access functions are whitelisted, thus one can for example use the <code>wal_size</code> metrics.</p> <p>Note</p> <p>By default Azure has pg_stat_statements not fully activated by default, so you need to enable it manually or via the API. Documentation link here.</p>"},{"location":"howto/using_managed_services.html#aiven-for-postgresql","title":"Aiven for PostgreSQL","text":"<p>The Aiven developer documentation contains information on how to monitor PostgreSQL instances running on the Aiven platform with pgwatch.</p>"},{"location":"intro/features.html","title":"List of main features","text":"<ul> <li>Non-invasive setup on PostgreSQL side - no extensions nor superuser     rights are required for the base functionality so that even     unprivileged users like developers can get a good overview of     database activities without any hassle</li> <li>Lots of preset metric configurations covering all performance     critical PostgreSQL internal Statistics Collector data</li> <li>Intuitive metrics presentation using a set of predefined dashboards     for the very popular Grafana dashboarding engine with optional     alerting support</li> <li>Easy extensibility of metrics which are defined in pure SQL, thus     they could also be from the business domain</li> <li>Many metric data storage options - PostgreSQL, PostgreSQL with the     compression enabled TimescaleDB extension, Prometheus scraping, or      gRPC-based custom storage integration</li> <li>Multiple deployment options - PostgreSQL configuration DB, YAML or     ENV configuration</li> <li>Possible to monitoring all, single or a subset (list or regex) of     databases of a PostgreSQL instance</li> <li>Global or per DB configuration of metrics and metric fetching     intervals</li> <li>Kubernetes/OpenShift ready with sample templates and a Helm chart</li> <li>PgBouncer, Pgpool2, AWS RDS and Patroni support with automatic     member discovery</li> <li>Internal REST API to monitor metrics gathering status remotely</li> <li>Built-in security with SSL connections support for all components     and passwords encryption for connect strings</li> <li>Very low resource requirements for the collector even when     monitoring hundreds of instances</li> <li>Capabilities to go beyond PostgreSQL metrics gathering with built-in     log parsing for error detection and OS level metrics collection via     PL/Python \"helper\" stored procedures</li> </ul>"},{"location":"intro/project_background.html","title":"Project background","text":"<p>The pgwatch project got started back in 2016 by Kaarel Moppel and released in 2017 initially for internal monitoring needs at Cybertec as all the Open Source PostgreSQL monitoring tools at the time had various limitations like being too slow and invasive to set up or providing a fixed set of visuals and metrics.</p> <p>For more background on the project motivations and design goals see the original series of blogposts announcing the project and the following feature updates released approximately twice per year.</p> <p>Cybertec also provides commercial 9-to-5 and 24/7 support for pgwatch.</p> <ul> <li>Project     announcement</li> <li>Implementation     details</li> <li>Feature pack     1</li> <li>Feature pack     2</li> <li>Feature pack     3</li> <li>Feature pack     4</li> <li>Feature pack     5</li> <li>Feature pack     6</li> <li>Feature pack     7</li> </ul>"},{"location":"intro/project_background.html#project-feedback","title":"Project feedback","text":"<p>For feature requests or troubleshooting assistance please open an issue on project's Github page.</p>"},{"location":"reference/advanced_features.html","title":"Advanced features","text":"<p>Over the years the core functionality of fetching metrics from a set of plain Postgres DB-s has been extended in many ways to cover some common problem areas like server log monitoring and supporting monitoring of some other popular tools often used together with Postgres, like the PgBouncer connection pooler for example.</p>"},{"location":"reference/advanced_features.html#patroni-support","title":"Patroni support","text":"<p>Patroni is a popular Postgres specific HA-cluster manager that makes node management simpler than ever, meaning that everything is dynamic though - cluster members can come and go, making monitoring in the standard way a bit tricky. But luckily Patroni cluster members information is stored in a DCS (Distributed Consensus Store), like etcd, so it can be fetched from there periodically.</p> <p>When 'patroni' is selected as a source type then the connection string should point to the DCS, and then pgwatch will periodically scan the DCS and add any found and not yet monitored: If you use etcd as the DCS, then your connection string should look like this: <code>etcd://host:port[,host:port..]/namespace/scope</code>, for example <code>etcd://localhost:2379/service/batman</code>.</p> <p>For YAML based setups an example can be found from the instances.yaml file.</p> <p>If Patroni is powered by etcd, then also username, password, ca_file, cert_file, key_file optional security parameters can be defined in the connection string, for example  <code>etcd://username:password@localhost:2379/service/batman?ca_file=/path/to/ca.crt&amp;cert_file=/path/to/client.crt&amp;key_file=/path/to/client.key</code>.</p> <p>Also, if you don't use the standby nodes actively for queries then it might make sense to decrease the volume of gathered metrics and to disable the monitoring of such nodes with the \"Primary mode only\".</p>"},{"location":"reference/advanced_features.html#log-parsing","title":"Log parsing","text":"<p>As of v1.7.0 the metrics collector daemon, when running on a DB server (controlled best over a YAML config), has capabilities to parse the database server logs for errors. Out-of-the-box it will though only work when logs are written in CSVLOG format. For other formats user needs to specify a regex that parses out named groups of following fields: database_name, error_severity. See here for an example regex.</p> <p>Note that only the event counts are stored, no error texts, usernames or other infos! Errors are grouped by severity for the monitored DB and for the whole instance. The metric name to enable log parsing is \"server_log_event_counts\". Also note that for auto-detection of log destination / setting to work, the monitoring user needs superuser / pg_monitor privileges - if this is not possible then log settings need to be specified manually under \"Host config\" as seen for example here.</p> <p>Sample configuration if not using CSVLOG logging:</p> <p>On Postgres side (on the monitored DB)</p> <pre><code>    # Debian / Ubuntu default log_line_prefix actually\n    log_line_prefix = '%m [%p] %q%u@%d '\n</code></pre> <p>YAML config (recommended when \"pushing\" metrics from DB nodes to a central metrics DB)</p> <pre><code>    ## logs_glob_path is only needed if the monitoring user is cannot auto-detect it (i.e. not a superuser / pg_monitor role)\n    # logs_glob_path:\n    logs_match_regex: '^(?P&lt;log_time&gt;.*) \\[(?P&lt;process_id&gt;\\d+)\\] (?P&lt;user_name&gt;.*)@(?P&lt;database_name&gt;.*?) (?P&lt;error_severity&gt;.*?): '\n</code></pre> <p>For log parsing to work the metric server_log_event_counts needs to be enabled or a preset config including it used - like the \"full\" preset.</p>"},{"location":"reference/advanced_features.html#pgbouncer-support","title":"PgBouncer support","text":"<p>pgwatch also supports collecting internal statistics from the PgBouncer connection pooler, via the built-in special \"pgbouncer\" database and the <code>SHOW STATS</code> command. To enable it choose the according DB Type, provide connection info to the pooler port and make sure the pgbouncer_stats metric or \"pgbouncer\" preset config is selected for the host. Note that for the \"DB Name\" field you should insert not \"pgbouncer\" (although this special DB provides all the statistics) but the real name of the pool you wish to monitor or leave it empty to track all pools. In latter case individual pools will be identified / separated via the \"database\" tag.</p> <p>There's also a built-in Grafana dashboard for PgBouncer data, looking like that:</p> <p></p>"},{"location":"reference/advanced_features.html#pgpool-ii-support","title":"Pgpool-II support","text":"<p>Quite similar to PgBouncer, also Pgpool offers some statistics on pool performance and status, which might be of interest especially if using the load balancing features. To enable it choose the according DB Type, provide connection info to the pooler port and make sure the pgpool_stats and pgpool_processes metrics or pgpool preset config is selected for the host.</p> <p>The built-in Grafana dashboard for Pgpool data looks something like that:</p> <p></p>"},{"location":"reference/advanced_features.html#prometheus-scraping","title":"Prometheus scraping","text":"<p>pgwatch was originally designed with direct metrics storage in mind, but later also support for externally controlled Prometheus scraping was added.</p> <p>To enable the scraping endpoint, add this commandline parameter: <code>--sink=prometheus://&lt;host&gt;:&lt;port&gt;/&lt;namespace&gt;</code>. If you omit host (Ex: <code>--sink=prometheus://:9187</code>), server listens on all interfaces and supplied port. If you omit namespace, default is <code>pgwatch</code>.</p> <p>Additionally, note that you still need to specify some metrics config as usual - only metrics with interval values bigger than zero will be populated on scraping.</p> <p>Currently, a few built-in metrics that require some state to be stored between scrapes, e.g. the \"change_events\" metric, will currently be ignored. Also, non-numeric data columns will be ignored! Tag columns will be preserved though as Prometheus \"labels\".</p>"},{"location":"reference/advanced_features.html#cloud-providers-support","title":"Cloud providers support","text":"<p>Due to popularity of various managed PostgreSQL offerings there's also support for some managed options in sense of Preset Configs, that take into account the fact that on such platforms you get a limited user that doesn't have access to all metrics or some features have just been plain removed. Thus, to reduce server log errors and save time on experimenting there are following presets available:</p> <ul> <li>aws - for standard AWS RDS managed PostgreSQL databases</li> <li>aurora - for AWS Aurora managed PostgreSQL service</li> <li>azure - for Azure Database for PostgreSQL managed databases</li> <li>gce - for Google Cloud SQL for PostgreSQL managed databases</li> </ul>"},{"location":"reference/cli_env.html","title":"Command-Line Options & Environment Variables","text":""},{"location":"reference/cli_env.html#general-usage","title":"General Usage","text":"<pre><code>  pgwatch [OPTIONS] [config | metric | source]\n</code></pre> <p>When no command is specified, the default is to start in a monitoring mode. pgwatch will read the configuration from the specified sources and metrics first, and then will start the measurements collection from resolved databases.</p>"},{"location":"reference/cli_env.html#options","title":"Options","text":""},{"location":"reference/cli_env.html#sources","title":"Sources","text":"<ul> <li> <p><code>-s</code>, <code>--sources=</code></p> <p>Postgres URI, file or folder of YAML files containing info on which DBs to monitor. ENV: <code>$PW_SOURCES</code></p> <p>Examples: <code>postgresql://pgwatch@localhost:5432/pgwatch</code>, <code>/etc/sources.yaml</code>, <code>/etc/pgwatch/sources/</code></p> </li> <li> <p><code>--refresh=</code></p> <p>How frequently to resync sources and metrics (default: 120). ENV: <code>$PW_REFRESH</code></p> </li> <li> <p><code>-g</code>, <code>--group=</code></p> <p>Groups for filtering which databases to monitor. By default all are monitored. ENV: <code>$PW_GROUP</code></p> </li> <li> <p><code>--min-db-size-mb=</code></p> <p>Smaller size databases will be ignored and not monitored until they reach the threshold (default: 0). ENV: <code>$PW_MIN_DB_SIZE_MB</code></p> </li> <li> <p><code>--max-parallel-connections-per-db=</code></p> <p>Max parallel metric fetches per monitored database. Note the multiplication effect on multi-DB instances (default: 4). ENV: <code>$PW_MAX_PARALLEL_CONNECTIONS_PER_DB</code></p> </li> <li> <p><code>--try-create-listed-exts-if-missing=</code></p> <p>Try creating the listed extensions (comma sep.) on first connect for all monitored DBs when missing. Main usage - pg_stat_statements. ENV: <code>$PW_TRY_CREATE_LISTED_EXTS_IF_MISSING</code></p> <p>Example: <code>pg_stat_statements,pg_hint_plan</code></p> </li> </ul>"},{"location":"reference/cli_env.html#metrics","title":"Metrics","text":"<ul> <li> <p><code>-m</code>, <code>--metrics=</code></p> <p>Postgres URI, YAML file or folder of YAML files with metrics definitions. ENV: <code>$PW_METRICS</code></p> </li> <li> <p><code>--create-helpers</code></p> <p>Create helper database objects from metric definitions. ENV: <code>$PW_CREATE_HELPERS</code></p> </li> <li> <p><code>--direct-os-stats</code></p> <p>Extract OS related psutil statistics not via PL/Python wrappers but directly on host. ENV: <code>$PW_DIRECT_OS_STATS</code></p> </li> <li> <p><code>--instance-level-cache-max-seconds=</code></p> <p>Max allowed staleness for instance level metric data shared between DBs of an instance. Set to 0 to disable (default: 30). ENV: <code>$PW_INSTANCE_LEVEL_CACHE_MAX_SECONDS</code></p> </li> <li> <p><code>--emergency-pause-triggerfile=</code></p> <p>When the file exists no metrics will be temporarily fetched / scraped (default: /tmp/pgwatch-emergency-pause). ENV: <code>$PW_EMERGENCY_PAUSE_TRIGGERFILE</code></p> </li> </ul>"},{"location":"reference/cli_env.html#sinks","title":"Sinks","text":"<ul> <li> <p><code>--sink=</code></p> <p>URI where metrics will be stored, can be used multiple times. ENV: <code>$PW_SINK</code></p> <p>Examples: <code>postgresql://pgwatch@localhost:5432/metrics</code>, <code>prometheus://localhost:9090</code>, <code>jsonfile:///tmp/metrics.json</code>, <code>grpc://user:pwd@localhost:5000/?sslrootca=/home/user/ca.crt</code></p> <p>See Sinks Options &amp; Parameters for more details.</p> </li> <li> <p><code>--batching-delay=</code></p> <p>Sink-specific batching flush delay; may be ignored by some sinks (default: 950ms). ENV: <code>$PW_BATCHING_DELAY</code></p> </li> <li> <p><code>--retention=</code></p> <p>If set, metrics older than that will be deleted (default: 14). ENV: <code>$PW_RETENTION</code></p> </li> <li> <p><code>--real-dbname-field=</code></p> <p>Tag key for real database name (default: real_dbname). ENV: <code>$PW_REAL_DBNAME_FIELD</code></p> </li> <li> <p><code>--system-identifier-field=</code></p> <p>Tag key for system identifier value (default: sys_id). ENV: <code>$PW_SYSTEM_IDENTIFIER_FIELD</code></p> </li> </ul>"},{"location":"reference/cli_env.html#logging","title":"Logging","text":"<ul> <li> <p><code>--log-level=[debug|info|error]</code></p> <p>Verbosity level for stdout and log file (default: info)</p> </li> <li> <p><code>--log-file=</code></p> <p>File name to store logs</p> </li> <li> <p><code>--log-file-format=[json|text]</code></p> <p>Format of file logs (default: json)</p> </li> <li> <p><code>--log-file-rotate</code></p> <p>Rotate log files</p> </li> <li> <p><code>--log-file-size=</code></p> <p>Maximum size in MB of the log file before it gets rotated (default: 100)</p> </li> <li> <p><code>--log-file-age=</code></p> <p>Number of days to retain old log files, 0 means forever (default: 0)</p> </li> <li> <p><code>--log-file-number=</code></p> <p>Maximum number of old log files to retain, 0 to retain all (default: 0)</p> </li> </ul>"},{"location":"reference/cli_env.html#webui","title":"WebUI","text":"<ul> <li> <p><code>--web-disable=[all|ui]</code></p> <p>Disable REST API and/or web UI. ENV: <code>$PW_WEBDISABLE</code></p> </li> <li> <p><code>--web-addr=</code></p> <p>TCP address in the form 'host:port' to listen on (default: :8080). ENV: <code>$PW_WEBADDR</code></p> </li> <li> <p><code>--web-user=</code></p> <p>Admin login. ENV: <code>$PW_WEBUSER</code></p> </li> <li> <p><code>--web-password=</code></p> <p>Admin password. ENV: <code>$PW_WEBPASSWORD</code></p> </li> </ul>"},{"location":"reference/cli_env.html#help-options","title":"Help Options","text":"<ul> <li> <p><code>-h</code>, <code>--help</code></p> <p>Show this help message</p> </li> </ul>"},{"location":"reference/cli_env.html#available-commands","title":"Available commands","text":""},{"location":"reference/cli_env.html#manage-configurations","title":"Manage configurations","text":"<pre><code>  pgwatch [OPTIONS] config &lt;init | upgrade&gt;\n</code></pre> <p>Info</p> <p>To use <code>config</code> command, you need to specify the <code>-s</code>, <code>--sources</code> and\\or <code>-m</code>, <code>--metrics</code> options.</p> <ul> <li> <p><code>init</code></p> <p>Initialize the configuration database with the required tables and functions. If file is used, it will be created in the specified location and filled with built-in defaults.</p> </li> <li> <p><code>upgrade</code></p> <p>Upgrade the database to the latest version. File or folder based configurations are not supported yet.</p> </li> </ul>"},{"location":"reference/cli_env.html#manage-metrics","title":"Manage metrics","text":"<pre><code>  pgwatch [OPTIONS] metric &lt;print-init | print-sql&gt;\n</code></pre> <p>Info</p> <p>To use <code>config</code> command, you need to specify the <code>-m</code>, <code>--metrics</code> option.</p> <ul> <li> <p><code>print-init</code></p> <p>Get and print init SQL for a given metric(s) or preset(s)</p> <p>Examples: <code>pgwatch metric print-init bgwriter cpu_load</code>, <code>pgwatch metric print-init exhaustive</code></p> </li> <li> <p><code>print-sql</code></p> <p>Get and print SQL for a given metric. Optional parameter <code>-v, --version=</code> specifies PostgreSQL version to get SQL for.</p> <p>Examples: <code>pgwatch metric print-sql bgwriter</code>, <code>pgwatch metric print-sql bgwriter -v 14</code></p> </li> </ul>"},{"location":"reference/cli_env.html#manage-sources","title":"Manage sources","text":"<pre><code>    pgwatch [OPTIONS] source &lt;ping | resolve&gt;\n</code></pre> <p>Info</p> <p>To use <code>source</code> command, you need to specify the <code>-s</code>, <code>--sources</code> option.</p> <ul> <li> <p><code>ping</code></p> <p>Ping the sources (databases, patroni clusters, poolers, etc.) to check if they are reachable.  </p> </li> <li> <p><code>resolve</code></p> <p>Resolve the monitored databases from sources (postgres clusters and patroni clusters) to check if they are reachableand if the configuration is correct. The output will be a list of the resolved databases with their connection strings.</p> </li> </ul>"},{"location":"reference/env_variables.html","title":"Available env. variables by components","text":"<p>Some variables influence multiple components. Command line parameters override env. variables (when doing custom deployments).</p>"},{"location":"reference/env_variables.html#docker-image-specific","title":"Docker image specific","text":"<ul> <li>PW_TESTDB When set, the config DB itself will be added to monitoring as \"test\". Default: -</li> </ul>"},{"location":"reference/env_variables.html#gatherer-daemon","title":"Gatherer daemon","text":"<p>See <code>pgwatch --help</code> output for details.</p>"},{"location":"reference/env_variables.html#grafana","title":"Grafana","text":"<ul> <li>PW_GRAFANANOANONYMOUS Can be set to require login even for viewing dashboards. Default: -</li> <li>PW_GRAFANAUSER Administrative user. Default: admin</li> <li>PW_GRAFANAPASSWORD Administrative user password. Default: pgwatchadmin</li> <li>PW_GRAFANASSL Use SSL. Default: -</li> <li>PW_GRAFANA_BASEURL For linking to Grafana \"Query details\" dashboard from \"Stat_stmt. overview\". Default: http://0.0.0.0:3000</li> </ul>"},{"location":"reference/metric_definitions.html","title":"Metric definitions","text":""},{"location":"reference/metric_definitions.html#what-is-a-metric","title":"What is a metric?","text":"<p>Metrics are named SQL queries that return a timestamp and anything else you find helpful. Most metrics have different query text versions for different target PostgreSQL versions, also optionally considering primary and/or replica states.</p> <pre><code>-- a sample metric\nSELECT\n  (extract(epoch from now()) * 1e9)::int8 as epoch_ns,\n  extract(epoch from (now() - pg_postmaster_start_time()))::int8 as postmaster_uptime_s,\n  case when pg_is_in_recovery() then 1 else 0 end as in_recovery_int;\n</code></pre> <p>The correct version of the metric definition will be chosen automatically by regularly connecting to the target database and checking the Postgres version, recovery state, and if the monitoring user is a superuser or not.</p>"},{"location":"reference/metric_definitions.html#what-is-a-preset","title":"What is a preset?","text":"<p>Presets in pgwatch are named collections of <code>metric_name: time interval</code> pairs, defined once and reused across multiple monitoring targets for convenience and consistency.</p>"},{"location":"reference/metric_definitions.html#built-in-metrics-and-presets","title":"Built-in metrics and presets","text":"<p>There's a good set of pre-defined metrics, metrics configs, and presets provided by the pgwatch project to cover all typical needs. However, when monitoring hundreds of hosts, you'd typically want to define custom metrics and/or presets or at least adjust the metric fetching intervals according to your monitoring goals.</p> <p>You can find the full list in pgwatch's default metrics.yaml file, for a more user-friendly experience, consider browsing them via the Web UI</p> <p>Some things to note about the built-in metrics:</p> <ul> <li>Only half of them are included in the Preset configs and are ready for direct usage. The rest need extra extensions or privileges, OS-level tool installations, etc. To see what's possible, just browse the sample metrics.</li> <li>Some built-in metrics are marked to be only executed when a server is a primary or, conversely, a standby. One can inspect the flags and set them on the Web UI Metrics tab or in the YAML file, changing the metric definition.</li> <li>Some unique preset metrics have some non-standard behavior attached to them, e.g., <code>change_events</code>, <code>server_log_event_counts</code>, <code>instance_up</code>, etc.</li> </ul>"},{"location":"reference/metric_definitions.html#custom-metrics","title":"Custom metrics","text":"<p>To work with custom metrics definitions, you should adhere to a couple of basic concepts:</p> <ul> <li> <p>Every metric query should have an <code>epoch_ns</code> (nanoseconds since epoch column) to record the metrics reading time. If the column is not there, things will still work, but the server timestamp of the metrics gathering daemon will be used, so a slight loss (assuming intra-datacenter monitoring with little lag) of precision occurs.</p> </li> <li> <p>Queries should only return text, integer, boolean, or floating point (a.k.a. double precision) Postgres data types. Note that columns with NULL values are not stored in the data layer, as it's a bit bothersome to work with NULLs!</p> </li> <li> <p>Column names should be descriptive enough so that they're self-explanatory, but not too long as it costs storage.</p> </li> <li> <p>Metric queries should execute fast - at least below the selected Statement timeout (default 5s).</p> </li> <li> <p>Columns can be optionally \"tagged\" by prefixing them with <code>tag_</code>. By doing this, the column data will be indexed by Postgres, providing the sophisticated auto-discovery support for indexed keys/values when building charts with Grafana and faster queries on those columns.</p> </li> <li> <p>All fetched metric rows can be \"prettified\" with custom static key-value data per host. Use the \"Custom tags\" Web UI field for the monitored DB entry or the \"custom_tags\" YAML field. Note that this works per host and applies to all metrics.</p> </li> <li> <p>For Prometheus the numerical columns are by default mapped to a Value Type of \"Counter\" (as most Statistics Collector columns are cumulative), but when this is not the case and the column is a \"Gauge\" then according column attributes should be declared. See the section on column attributes for details.</p> </li> <li> <p>For Prometheus all text fields will be turned into tags/labels as only floats can be stored!</p> </li> </ul>"},{"location":"reference/metric_definitions.html#adding-and-using-a-custom-metric","title":"Adding and using a custom metric","text":""},{"location":"reference/metric_definitions.html#for-config-db-based-setups","title":"For Config DB based setups","text":"<p>Info</p> <p>The default <code>metrics.yml</code> file is loaded into the config DB on bootstrap no need to add it manually.</p> <ol> <li>Go to the Web UI \"METRICS\" page and press the \"+ NEW\" button.</li> <li>Fill out the template - pick a name for your metric, select the minimum  supported PostgreSQL version, and insert the query text and any  extra attributes, if any (see below for options). Hit the \"ADD METRIC\"  button to store.</li> <li>Activate the newly added metric by including it in some existing \u00a0 \u00a0 Preset Config in the \"PRESETS\" page or add it directly to the monitored DB,  together with an interval, into the \"METRICS\" tab when editing a source on the \"SOURCES\" page.</li> </ol>"},{"location":"reference/metric_definitions.html#for-yaml-based-setups","title":"For YAML based setups","text":"<ol> <li>Edit or create a copy of the <code>metrics.yaml</code> file shipped with the installation.</li> <li>Add a new entry to the <code>metrics</code> array and optionally add a new metric in some existing or new Preset.</li> </ol> <p>Here is the structure of a metric definition in YAML format:</p> <pre><code>    metric_name:\n        description: \"A short description of the metric\"\n        init_sql: |\n            CREATE EXTENSION IF NOT EXISTS some_extension;\n            CREATE OR REPLACE FUNCTION get_some_stat(OUT some_stat int)\n            ...\n        sqls:\n            11: |\n                select /* pgwatch_generated */\n                (extract(epoch from now()) * 1e9)::int8 as epoch_ns,\n                ...\n            14: |\n                select /* pgwatch_generated */\n                (extract(epoch from now()) * 1e9)::int8 as epoch_ns,\n                ...\n        gauges:\n            - some_column1\n            - some_column2\n            - * # for all columns\n        is_instance_level: true\n        node_status: primary/standby\n        statement_timeout_seconds: 300\n        metric_storage_name: some_other_metric_name\n</code></pre> <ul> <li> <p>init_sql</p> <p>Optional SQL code that must be executed before the metric query itself. DBA can use it to create helper functions, install extensions, etc. Usually executed during the preparation database for monitoring with superuser privileges.</p> <p>As mentioned in Metrics initialization section, Postgres knows very little about the operating system that it's running on, so in some cases, it might be advantageous to also monitor some basic OS statistics together with the PostgreSQL ones to get a better head start when troubleshooting performance problems. But as setup of such OS tools and linking the gathered data is not always trivial, pgwatch has a system of helpers for fetching such data.</p> <p>One can invent and install such helpers on the monitored databases freely to expose any information needed via Python, or any other procedure language supported by Postgres.</p> </li> <li> <p>sqls</p> <p>The actual metric query texts. The key is the minimum supported PostgreSQL version. The query text should be a valid SQL query that returns a timestamp column named <code>epoch_ns</code> and any other columns you want to store. The <code>pgwatch_generated</code> comment is good for debugging purposes and filtering out the queries from the logs.</p> <p>Notice</p> <p>Note the \"minimally supported\" part - i.e. if your query will work from version v11.x to v17.x, then you only need one entry called \"11\". If there was a breaking change in the internal catalogs at v13 so that the query stopped working, you need a new entry named \"13\" that will be used for all versions above v13.</p> </li> <li> <p>gauges</p> <p>List of columns that should be treated as gauges. By default, all columns are treated as counters. Gauges are metrics that can go up and down, like the number of active connections. Counters are metrics that only go up, like the number of queries executed. This property is only relevant for Prometheus output.</p> </li> <li> <p>is_instance_level</p> <p>Enables caching, i.e., sharing of metric data between various databases of a single instance to reduce the load on the monitored server.</p> </li> <li> <p>node_status</p> <p>If set to \"primary\" or \"standby,\" the metric will only be executed when the server is in that state. This property is helpful for only relevant metrics for primary or standby servers.</p> </li> <li> <p>statement_timeout_seconds</p> <p>The maximum time in seconds the metric query is allowed to run before it's killed. The default is 5 seconds.</p> </li> <li> <p>metric_storage_name</p> <p>Enables dynamic \"renaming\" of metrics at the storage level, i.e. declaring almost similar metrics with different names, but the data will be stored under one metric. Currently used (for out-of-the-box metrics) only for the <code>stat_statements_no_query_text</code> metric to not store actual query texts from the \"pg_stat_statements\" extension for more security-sensitive instances.</p> </li> </ul>"},{"location":"reference/rest.html","title":"REST API Reference","text":"<p>pgwatch provides a RESTful API for managing monitoring sources, metrics, and presets. All endpoints require authentication unless explicitly noted.</p>"},{"location":"reference/rest.html#authentication","title":"Authentication","text":"<p>Most endpoints require authentication via JWT token. Obtain a token using the login endpoint:</p> <pre><code>$ curl -X POST http://localhost:8080/login \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"user\": \"your_username\", \"password\": \"your_password\"}'\n\neyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhdXRob3JpemVkIjp0cnVlLCJleHAiOjE3NTI3MDY0OTYsInVzZXJuYW1lIjoieW91cl91c2VybmFtZSJ9.sPpNgpqtjZJqNfgfmypdR3rvlPQxxMtsg2v2WLPVbUA\n</code></pre> <p>Use the returned token in the Authorization header for subsequent requests:</p> <pre><code># Set token as environment variable (copy the token from login response)\nexport TOKEN=\"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhdXRob3JpemVkIjp0cnVlLCJleHAiOjE3NTI3MDY0OTYsInVzZXJuYW1lIjoieW91cl91c2VybmFtZSJ9.sPpNgpqtjZJqNfgfmypdR3rvlPQxxMtsg2v2WLPVbUA\"\n\n# Or capture token automatically in one command\nTOKEN=$(curl -s -X POST http://localhost:8080/login \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"user\": \"your_username\", \"password\": \"your_password\"}')\n\n# Use in requests (note: pgwatch uses 'Token' header, not 'Authorization: Bearer')\n$ curl -H \"Token: $TOKEN\" http://localhost:8080/source\n</code></pre>"},{"location":"reference/rest.html#health-check-apis","title":"Health Check APIs","text":""},{"location":"reference/rest.html#liveness-probe","title":"Liveness probe","text":"<p>Check if the service is running (no authentication required).</p> <pre><code>curl -X GET http://localhost:8080/liveness\n</code></pre> <p>Response: <code>{\"status\": \"ok\"}</code> if service is alive</p>"},{"location":"reference/rest.html#readiness-probe","title":"Readiness probe","text":"<p>Check if the service is ready to serve requests (no authentication required).</p> <pre><code>$ curl -X GET http://localhost:8080/readiness\n</code></pre> <p>Response: <code>{\"status\": \"ok\"}</code> if service is ready</p>"},{"location":"reference/rest.html#api-patterns","title":"API Patterns","text":"<p>pgwatch uses different request patterns for different resource types:</p>"},{"location":"reference/rest.html#collection-vs-item-endpoints","title":"Collection vs Item Endpoints","text":"<ul> <li>Collection endpoints (<code>/metric</code>, <code>/preset</code>): Used for listing all resources with GET and creating new resources with POST</li> <li>Item endpoints (<code>/metric/{name}</code>, <code>/preset/{name}</code>): Used for reading, updating, or deleting specific resources</li> </ul>"},{"location":"reference/rest.html#request-body-formats","title":"Request Body Formats","text":"<p>Sources use direct object format:</p> <pre><code>{\n  \"Name\": \"my-postgres\",\n  \"Kind\": \"postgres\",\n  \"ConnStr\": \"postgresql://...\",\n  \"IsEnabled\": true\n}\n</code></pre> <p>Metrics and Presets use collection format for creation (POST to collection endpoint):</p> <pre><code>{\n  \"resource_name\": {\n    \"field1\": \"value1\",\n    \"field2\": \"value2\"\n  }\n}\n</code></pre> <p>But use direct object format for updates (PUT to item endpoint):</p> <pre><code>{\n  \"field1\": \"updated_value1\",\n  \"field2\": \"updated_value2\"\n}\n</code></pre>"},{"location":"reference/rest.html#sources-api","title":"Sources API","text":""},{"location":"reference/rest.html#list-all-sources","title":"List all sources","text":"<p>Get all monitoring sources.</p> <pre><code>$ curl -H \"Token: $TOKEN\" -X GET http://localhost:8080/source\n</code></pre> <p>Response: JSON array of source objects</p>"},{"location":"reference/rest.html#create-source","title":"Create source","text":"<p>Add a new monitoring source.</p> <pre><code>$ curl -X POST http://localhost:8080/source \\\n  -H \"Token: $TOKEN\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"Name\": \"my-postgres\",\n    \"Kind\": \"postgres\",\n    \"Group\": \"default\",\n    \"ConnStr\": \"postgresql://user:pass@localhost:5432/dbname\",\n    \"PresetMetrics\": \"exhaustive\",\n    \"IsEnabled\": true\n  }'\n</code></pre>"},{"location":"reference/rest.html#get-specific-source","title":"Get specific source","text":"<p>Retrieve a specific source by name.</p> <pre><code>$ curl -H \"Token: $TOKEN\" -X GET http://localhost:8080/source/my-postgres\n</code></pre> <p>Response: JSON object with source details</p>"},{"location":"reference/rest.html#update-specific-source","title":"Update specific source","text":"<p>Update an existing source using PUT method.</p> <pre><code>$ curl -X PUT http://localhost:8080/source/my-postgres \\\n  -H \"Token: $TOKEN\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"Name\": \"my-postgres\",\n    \"Kind\": \"postgres\",\n    \"Group\": \"default\",\n    \"ConnStr\": \"postgresql://user:pass@localhost:5432/dbname\",\n    \"PresetMetrics\": \"exhaustive\",\n    \"IsEnabled\": false\n  }'\n</code></pre>"},{"location":"reference/rest.html#delete-specific-source","title":"Delete specific source","text":"<p>Remove a monitoring source.</p> <pre><code>$ curl -H \"Token: $TOKEN\" -X DELETE http://localhost:8080/source/my-postgres\n</code></pre>"},{"location":"reference/rest.html#test-connection","title":"Test connection","text":"<p>Test connectivity to a PostgreSQL instance. This endpoint allows you to verify that the connection string is valid and the database is reachable from the pgwatch environment.</p> <pre><code>$ curl -X POST http://localhost:8080/test-connect \\\n  -H \"Token: $TOKEN\" \\\n  -H \"Content-Type: application/json\" \\\n  -d 'postgresql://user:pass@localhost:5432/dbname'\n</code></pre>"},{"location":"reference/rest.html#metrics-api","title":"Metrics API","text":""},{"location":"reference/rest.html#list-all-metrics","title":"List all metrics","text":"<p>Get all available metrics definitions.</p> <pre><code>$ curl -H \"Token: $TOKEN\" -X GET http://localhost:8080/metric\n</code></pre> <p>Response: JSON array of metric objects</p>"},{"location":"reference/rest.html#create-metric","title":"Create metric","text":"<p>Add a new metric definition. POST to the collection endpoint expects a map with metric name as key.</p> <p>Note</p> <p>You can create multiple metrics in a single request by providing multiple key-value pairs.</p> <pre><code>$ curl -X POST http://localhost:8080/metric \\\n  -H \"Token: $TOKEN\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"custom_metric\": {\n      \"SQLs\": {\n        \"11\": \"SELECT count(*) as active_connections FROM pg_stat_activity\"\n      },\n      \"Description\": \"Number of active connections\"\n    }\n  }'\n</code></pre> <p>Bulk creation example:</p> <pre><code>$ curl -X POST http://localhost:8080/metric \\\n  -H \"Token: $TOKEN\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"metric_one\": {\n      \"SQLs\": {\"11\": \"SELECT 1\"},\n      \"Description\": \"First metric\"\n    },\n    \"metric_two\": {\n      \"SQLs\": {\"11\": \"SELECT 2\"},\n      \"Description\": \"Second metric\"\n    }\n  }'\n</code></pre>"},{"location":"reference/rest.html#get-specific-metric","title":"Get specific metric","text":"<p>Retrieve a specific metric definition by name.</p> <pre><code>$ curl -H \"Token: $TOKEN\" -X GET http://localhost:8080/metric/custom_metric\n</code></pre> <p>Response: JSON object with metric definition</p>"},{"location":"reference/rest.html#update-specific-metric","title":"Update specific metric","text":"<p>Update an existing metric definition using PUT method on the item endpoint.</p> <pre><code>$ curl -X PUT http://localhost:8080/metric/custom_metric \\\n  -H \"Token: $TOKEN\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"SQLs\": { \n        \"11\": \"SELECT count(*) as connections FROM pg_stat_activity WHERE state = $$active$$\"\n    },\n    \"Description\": \"Number of active connections (updated)\"\n  }'\n</code></pre>"},{"location":"reference/rest.html#delete-specific-metric","title":"Delete specific metric","text":"<p>Remove a metric definition.</p> <pre><code>$ curl -H \"Token: $TOKEN\" -X DELETE http://localhost:8080/metric/custom_metric\n</code></pre>"},{"location":"reference/rest.html#presets-api","title":"Presets API","text":""},{"location":"reference/rest.html#list-all-presets","title":"List all presets","text":"<p>Get all available metric presets.</p> <pre><code>$ curl -H \"Token: $TOKEN\" -X GET http://localhost:8080/preset\n</code></pre> <p>Response: JSON array of preset objects</p>"},{"location":"reference/rest.html#create-preset","title":"Create preset","text":"<p>Add a new preset. POST to the collection endpoint expects a map with preset name as key.</p> <p>Note</p> <p>You can create multiple presets in a single request by providing multiple key-value pairs.</p> <pre><code>$ curl -X POST http://localhost:8080/preset \\\n  -H \"Token: $TOKEN\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"custom_preset\": {\n      \"Description\": \"Custom monitoring preset\",\n      \"Metrics\": {\n        \"db_stats\": 60,\n        \"table_stats\": 300,\n        \"custom_metric\": 120\n      }\n    }\n  }'\n</code></pre>"},{"location":"reference/rest.html#get-specific-preset","title":"Get specific preset","text":"<p>Retrieve a specific preset by name.</p> <pre><code>$ curl -H \"Token: $TOKEN\" -X GET http://localhost:8080/preset/custom_preset\n</code></pre> <p>Response: JSON object with preset definition</p>"},{"location":"reference/rest.html#update-specific-preset","title":"Update specific preset","text":"<p>Update an existing preset using PUT method on the item endpoint.</p> <pre><code>$ curl -X PUT http://localhost:8080/preset/custom_preset \\\n  -H \"Token: $TOKEN\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"Description\": \"Updated custom monitoring preset\",\n    \"Metrics\": {\n      \"db_stats\": 30,\n      \"table_stats\": 600,\n      \"index_stats\": 300\n    }\n  }'\n</code></pre>"},{"location":"reference/rest.html#delete-specific-preset","title":"Delete specific preset","text":"<p>Remove a preset definition.</p> <pre><code>$ curl -H \"Token: $TOKEN\" -X DELETE http://localhost:8080/preset/custom_preset\n</code></pre>"},{"location":"reference/rest.html#options-requests","title":"Options Requests","text":"<p>All resource endpoints support OPTIONS requests to discover allowed methods:</p> <pre><code>$ curl -H \"Token: $TOKEN\" -X OPTIONS http://localhost:8080/source/my-postgres\n</code></pre> <p>Response: <code>Allow</code> header with supported methods (e.g., <code>GET, PUT, DELETE, OPTIONS</code>)</p>"},{"location":"reference/rest.html#http-status-codes","title":"HTTP Status Codes","text":"<ul> <li><code>200 OK</code> - Request successful</li> <li><code>201 Created</code> - Resource created successfully</li> <li><code>400 Bad Request</code> - Invalid request parameters</li> <li><code>401 Unauthorized</code> - Authentication required or invalid</li> <li><code>404 Not Found</code> - Resource not found</li> <li><code>405 Method Not Allowed</code> - HTTP method not supported for endpoint</li> <li><code>500 Internal Server Error</code> - Server error</li> </ul>"},{"location":"reference/sinks_options.html","title":"Sinks Options &amp; Parameters","text":""},{"location":"reference/sinks_options.html#postgresql","title":"PostgreSQL","text":"<p>The PostgreSQL sink URI format is the standard PostgreSQL connection string, e.g.</p> <pre><code>--sink=postgresql://user:pwd@host:port/dbname?sslmode=disable&amp;connect_timeout=10\n</code></pre> <p>All standard environment variables are supported as well.</p>"},{"location":"reference/sinks_options.html#prometheus","title":"Prometheus","text":"<p>The Prometheus sink URI format is</p> <pre><code>--sink=prometheus://host:port/namespace\n</code></pre> <p>If you omit host, e.g. <code>--sink=prometheus://:9187</code>, server listens on all interfaces and supplied port. If you omit namespace, default is <code>pgwatch</code>.</p>"},{"location":"reference/sinks_options.html#json-file","title":"JSON file","text":"<p>The JSON file sink URI format is</p> <pre><code>--sink=jsonfile:///path/to/file.json\n</code></pre> <p>It should be a valid file path where the JSON data will be written. If the file does not exist, it will be created.</p>"},{"location":"reference/sinks_options.html#grpc","title":"gRPC","text":"<p>The gRPC sink URI format is</p> <pre><code>--sink=grpc://user:pwd@host:port/?sslrootca=/path/to/ca.crt\n</code></pre> <p>The gRPC sink supports optional authentication and TLS encryption over the RPC channel.</p> <p>For authentication credentials can be provided using the <code>username:password</code> format in the URI string, e.g. <code>--sink=grpc://user:pwd@localhost:5000/</code>. If omitted, defaults to empty string for both username and password. The values are then forwarded to the gRPC server under the <code>\"username\"</code> and <code>\"password\"</code> fields in the metadata.</p> <p>Enable TLS by specifying a custom Certificate Authority (CA) file via the <code>sslrootca</code> URI parameter, e.g. <code>--sink=grpc://localhost:5000/?sslrootca=/home/user/ca.crt</code> If omitted, encryption is not used.</p>"},{"location":"tutorial/custom_installation.html","title":"Custom installation","text":"<p>As described in the Components chapter, there is a couple of ways how to set up pgwatch. Two most common ways though are using the central configuration database approach and the YAML file based approach, plus Grafana to visualize the gathered metrics.</p>"},{"location":"tutorial/custom_installation.html#configuration-database-based-setup","title":"Configuration Database based setup","text":""},{"location":"tutorial/custom_installation.html#overview-of-installation-steps","title":"Overview of installation steps","text":"<ol> <li>Install Postgres or use any available existing instance - v11+     is required but the latest major version is recommended.</li> <li>Bootstrap the configuration database.</li> <li>Bootstrap the metrics measurements storage database aka sink (PostgreSQL here).</li> <li>Install pgwatch - either from pre-built packages or by compiling     the Go code.</li> <li>Prepare the \"to-be-monitored\" databases for monitoring by creating     a dedicated login role name as a minimum.</li> <li>Add some databases to the monitoring configuration via the Web UI, REST API or     directly in the configuration database.</li> <li>Start the pgwatch metrics collection agent and monitor the logs for     any problems.</li> <li>Install and configure Grafana and import the pgwatch sample     dashboards to start analyzing the metrics.</li> <li>Make sure that there are auto-start services for all     components in place and optionally set up also backups.</li> </ol>"},{"location":"tutorial/custom_installation.html#detailed-steps-for-the-configuration-database-approach-with-postgres-sink","title":"Detailed steps for the configuration database approach with Postgres sink","text":"<p>Below are the sample steps for a custom installation from scratch using Postgres for the pgwatch configuration database, measurements database and Grafana configuration database.</p> <p>All examples here assume Ubuntu as OS but it's basically the same for RedHat family of operations systems also, minus package installation syntax differences.</p> <ol> <li> <p>Install Postgres</p> <p>Follow the standard Postgres install procedure basically. Use the latest major version available, but minimally v11+ is required.</p> <p>To get the latest Postgres versions, official Postgres PGDG repos are to be preferred over default disto repos. Follow the instructions from:</p> <ul> <li>https://www.postgresql.org/download/linux/debian/ - for Debian / Ubuntu     based systems</li> <li>https://www.postgresql.org/download/linux/redhat/ - for CentOS     / RedHat based systems</li> <li>https://www.postgresql.org/download/windows/ - for Windows</li> </ul> </li> <li> <p>Install pgwatch either from pre-built packages or by     compiling the Go code</p> <ul> <li> <p>Using pre-built packages which are available on the     GitHub releases     page:</p> <pre><code># find out the latest package link and replace below, using v3.0 here\nwget https://github.com/cybertec-postgresql/pgwatch/releases/download/3.0.0/pgwatch_Linux_x86_64.deb\nsudo dpkg -i pgwatch_Linux_x86_64.deb\n</code></pre> </li> <li> <p>Compiling the Go code yourself</p> <p>This method of course is not needed unless dealing with maximum security environments or some slight code changes are required.</p> <ol> <li> <p>Install Go by following the official     instructions</p> </li> <li> <p>Get the pgwatch project's code and compile the gatherer     daemon</p> <pre><code>git clone https://github.com/cybertec-postgresql/pgwatch.git\ncd pgwatch/internal/webui\nyarn install --network-timeout 100000 &amp;&amp; yarn build\ncd ../..\ngo build ./cmd/pgwatch/\n</code></pre> <p>After fetching all the Go library dependencies (can take minutes) an executable named \"pgwatch\" should be generated. Additionally, it's a good idea to copy it to <code>/usr/bin/pgwatch</code>.</p> </li> </ol> </li> <li> <p>Configure a SystemD auto-start service (optional). Here is the sample:</p> <pre><code>[Unit]\nDescription=pgwatch\nAfter=network-online.target\n\n# After=&lt;postgresql@17-main.service&gt;\n\n[Service]\nUser=pgwatch\nType=exec\nExecStart=/usr/bin/pgwatch --sources=postgresql://pgwatch:xyz@localhost:5432/pgwatch --sink=postgresql://pgwatch:xyz@localhost:5432/pgwatch_metrics\nRestart=on-failure\nTimeoutStartSec=0\n\n[Install]\nWantedBy=multi-user.target\n</code></pre> </li> </ul> </li> <li> <p>Bootstrap the configuration database</p> <p>Note</p> <p>The detailed steps are described in the Bootstrapping the Configuration Database chapter</p> <ul> <li> <p>Create a user to \"own\" the <code>pgwatch</code> database</p> <p>Typically called <code>pgwatch</code> but can be anything really, if the schema creation file is adjusted accordingly.</p> <pre><code>psql -c \"create user pgwatch password 'xyz'\"\npsql -c \"create database pgwatch owner pgwatch\"\n</code></pre> </li> <li> <p>Roll out the pgwatch config schema (optional)</p> <p>pgwatch will automatically create the necessary tables and indexes in the database when it starts. But in case you want to create the schema as a separate step, you can use the <code>config init</code> command-line command:</p> <pre><code>pgwatch --sources=postgresql://pgwatch:xyz@localhost/pgwatch config init\n</code></pre> </li> </ul> </li> <li> <p>Bootstrap the measurements storage database (sink)</p> <p>Note</p> <p>The detailed steps are described in the Bootstrapping the Metrics Measurements Database (Sink) chapter</p> <p>Create a dedicated database for storing metrics and a user to \"own\" the measurements schema. Here again default scripts expect a role named <code>pgwatch</code> but can be anything if to adjust the scripts:</p> <pre><code>psql -c \"create database pgwatch_metrics owner pgwatch\"\n</code></pre> </li> <li> <p>Prepare the \"to-be-monitored\" databases for metrics collection</p> <p>As a minimum we need a plain unprivileged login user. Better though is to grant the user also the <code>pg_monitor</code> system role, available on v10+. Superuser privileges should be normally avoided for obvious reasons of course, but for initial testing in safe environments it can make the initial preparation (automatic helper rollouts) a bit easier still, given superuser privileges are later stripped.</p> <p>To get most out of your metrics some <code>SECURITY DEFINER</code> wrappers functions called \"helpers\" are recommended on the DB-s under monitoring. See the detailed chapter on the \"preparation\" topic for more details.</p> </li> <li> <p>Start the pgwatch metrics collection agent</p> <p>The gatherer has quite some parameters (use the <code>--help</code> flag to show them all), but simplest form would be:</p> <pre><code>pgwatch \\\n    --sources=postgresql://pgwatch:xyz@localhost:5432/pgwatch \\\n    --sink=postgresql://pgwatch:xyz@localhost:5432/pgwatch_metrics \\\n    --log-level=debug\n</code></pre> <p>Or via SystemD if set up in previous steps</p> <pre><code>useradd -m -s /bin/bash pgwatch # default SystemD templates run under the pgwatch user\nsudo systemctl start pgwatch\nsudo systemctl status pgwatch\n</code></pre> <p>After initial verification that all works, it's usually good idea to set verbosity back to default by removing the --log-level=debug flag.</p> </li> <li> <p>Configure sources and metrics with intervals to be monitored</p> <ul> <li>from the Web UI \"Sources\" page</li> <li>via direct inserts into the Config DB <code>pgwatch.source</code> table</li> </ul> </li> <li> <p>Monitor the console or log output for any problems</p> <p>Wait for a few minutes or restart the gatherer daemon to reread the monitored sources and metrics configuration. You can control the refresh timeout via the <code>--refresh</code> parameter, default is 120 seconds.</p> <p>If you see metrics trickling into the \"pgwatch_metrics\" database (metric names are mapped to table names and tables are auto-created), then congratulations - the deployment is working! When using some more aggressive preset metrics config then there are usually still some errors though, due to the fact that some more extensions or privileges are missing on the monitored database side. See the according chapter.</p> </li> <li> <p>Install Grafana</p> <ol> <li> <p>Create a Postgres database to hold Grafana internal config, like     dashboards etc.</p> <p>Theoretically it's not absolutely required to use Postgres for storing Grafana internal settings, but doing so has 2 advantages - you can easily roll out all pgwatch built-in dashboards and one can also do remote backups of the Grafana configuration easily.</p> <pre><code>psql -c \"create user pgwatch_grafana password 'xyz'\"\npsql -c \"create database pgwatch_grafana owner pgwatch_grafana\"\n</code></pre> </li> <li> <p>Follow the instructions from Grafana documentation, basically something like:</p> <pre><code>wget -q -O - https://packages.grafana.com/gpg.key | sudo apt-key add -\necho \"deb https://packages.grafana.com/oss/deb stable main\" | sudo tee -a /etc/apt/sources.list.d/grafana.list\nsudo apt-get update &amp;&amp; sudo apt-get install grafana\n\n# review / change config settings and security, etc\nsudo vi /etc/grafana/grafana.ini\n\n# start and enable auto-start on boot\nsudo systemctl daemon-reload\nsudo systemctl start grafana-server\nsudo systemctl status grafana-server\n</code></pre> <p>Default Grafana port: 3000</p> </li> <li> <p>Configure Grafana config to use our <code>pgwatch_grafana</code> DB</p> <p>Place something like this below in the <code>[database]</code> section of <code>/etc/grafana/grafana.ini</code></p> <pre><code>[database]\ntype = postgres\nhost = my-postgres-db:5432\nname = pgwatch_grafana\nuser = pgwatch_grafana\npassword = xyz\n</code></pre> <p>Taking a look at <code>[server], [security]</code> and <code>[auth*]</code> sections is also recommended.</p> </li> <li> <p>Set up the <code>pgwatch</code> metrics database as the default datasource</p> <p>We need to tell Grafana where our metrics data is located. Add a datasource via the Grafana UI (Admin -&gt; Data sources) or use <code>pgwatch/grafana/postgres_datasource.yml</code> for provisioning.</p> </li> <li> <p>Add pgwatch predefined dashboards to Grafana</p> <p>This could be done by importing the pgwatch dashboard definition JSONs manually, one by one, from the <code>pgwatch/grafana</code> folder (\"Import Dashboard\" from the Grafana top menu) or by dashboard provisioning.</p> </li> <li> <p>Optionally install also Grafana plugins</p> <p>Currently, one pre-configured dashboard (Biggest relations treemap) use an extra plugin - if planning to use that dash, then run the following:</p> <pre><code>grafana-cli plugins install savantly-heatmap-panel\n</code></pre> </li> <li> <p>Start discovering the preset dashbaords</p> <p>If the previous step of launching pgwatch succeeded, and it was more than some minutes ago, one should already see some graphs on dashboards like \"DB overview\" or \"DB overview Unprivileged / Developer mode\" for example.</p> </li> </ol> </li> </ol>"},{"location":"tutorial/custom_installation.html#yaml-configuration-based-setup","title":"YAML Configuration based setup","text":"<p>The process is completely identical to the above, but instead of setting up a Postgres database for the configuration, one would use a YAML file. For details on individual steps like installing pgwatch see the above paragraph.</p> <ol> <li>Install Postgres or use any available existing instance - v11+     is required but the latest major version is recommended.</li> <li>Edit the YAML file to include the sources to be monitored.</li> <li>Bootstrap the metrics measurements storage database aka sink (PostgreSQL here).</li> <li>Install pgwatch - either from pre-built packages or by compiling     the Go code.</li> <li>Prepare the \"to-be-monitored\" databases for monitoring by creating     a dedicated login role name as a minimum.</li> <li>Add some databases to the monitoring configuration via the Web UI, REST API or     directly in the configuration database.</li> <li>Start the pgwatch metrics collection agent and monitor the logs for     any problems.</li> <li>Install and configure Grafana and import the pgwatch sample     dashboards to start analyzing the metrics.</li> <li>Make sure that there are auto-start services for all     components in place and optionally set up also backups.</li> </ol>"},{"location":"tutorial/custom_installation.html#yaml-configuration-file","title":"YAML Configuration file","text":"<p>The content of a file is a array of sources definitions, like this:</p> <pre><code>- name: test1       # An arbitrary unique name for the monitored source\n  kind: postgres    # One of the:\n                      # - postgres\n                      # - postgres-continuous-discovery\n                      # - pgbouncer\n                      # - pgpool\n                      # - patroni\n                      # - patroni-continuous-discovery\n                      # - patroni-namespace-discover\n                      # Defaults to postgres if not specified\n  conn_str: postgresql://pgwatch:xyz@somehost/mydb\n  preset_metrics: exhaustive # from list of presets defined in \"metrics/preset-configs.yaml\"\n  custom_metrics:    # if both preset and custom are specified, custom wins\n  preset_metrics_standby: # optional metrics configuration for standby / replica state, v1.8.1+\n  custom_metrics_standby:\n  include_pattern: # regex to filter databases to actually monitor for the \"continuous\" modes\n  exclude_pattern:\n  is_enabled: true\n  group: default # just for logical grouping of DB hosts or for \"sharding\", i.e. splitting the workload between many gatherer daemons\n  custom_tags:      # option to add arbitrary tags for every stored data row,\n      aws_instance_id: i-0af01c0123456789a       # for example to fetch data from some other source onto a same Grafana graph\n...\n</code></pre>"},{"location":"tutorial/docker_installation.html","title":"Installing using Docker","text":""},{"location":"tutorial/docker_installation.html#simple-setup-steps","title":"Simple setup steps","text":"<p>The simplest real-life pgwatch setup should look something like that:</p> <ol> <li> <p>Decide which metrics storage engine you want to use -     cybertecpostgresql/pgwatch-demo uses PostgreSQL.     When only Prometheus sink is used (exposing a     port for remote scraping), one should use the slimmer     cybertecpostgresql/pgwatch image which doesn't have any built in     databases.</p> </li> <li> <p>Find the latest pgwatch release version by going to the project's     GitHub Releases page or use the public API with something like     that:</p> </li> </ol> <pre><code>curl -so- https://api.github.com/repos/cybertec-postgresql/pgwatch/releases/latest | jq .tag_name | grep -oE '[0-9\\.]+'\n</code></pre> <ol> <li>Pull the image:</li> </ol> <pre><code>docker pull cybertecpostgresql/pgwatch-demo:X.Y.Z\n</code></pre> <ol> <li>Run the Docker image, exposing minimally the Grafana port served on     port 3000 internally. In a relatively secure environment you'd     usually also include the administrative web UI served on port 8080:</li> </ol> <pre><code>docker run -d --restart=unless-stopped -p 3000:3000 -p 8080:8080 \\\n--name pw3 cybertecpostgresql/pgwatch-demo:X.Y.Z\n</code></pre> <p>Note that we're setting the container to be automatically restarted in case of a reboot/crash - which is highly recommended if not using some container management framework to run pgwatch.</p>"},{"location":"tutorial/docker_installation.html#more-future-proof-setup-steps","title":"More future-proof setup steps","text":"<p>Although the above simple setup example will do for more temporal setups / troubleshooting sessions, for permanent setups it's highly recommended to create separate volumes for all software components in the container, so that it would be easier to update to newer pgwatch Docker images and pull file system based backups, and also it might be a good idea to expose all internal ports at least on localhost for possible troubleshooting and making possible to use native backup tools more conveniently for Postgres.</p> <p>Note that, for maximum flexibility, security and update simplicity it's best to do a custom setup though - see the next chapter for that.</p> <p>So in short, for plain Docker setups would be best to do something like:</p> <pre><code># let's create volumes for Postgres, Grafana and pgwatch marker files / SSL certificates\nfor v in pg  grafana pw3 ; do docker volume create $v ; done\n\n# launch pgwatch with fully exposed Grafana, Web UI, Postgres\ndocker run -d --restart=unless-stopped --name pw3 \\\n    -p 3000:3000 -p 127.0.0.1:5432:5432 -p 192.168.1.XYZ:8080:8080 \\\n    -v pg:/var/lib/postgresql/data -v grafana:/var/lib/grafana -v pw3:/pgwatch/persistent-config \\\n    cybertecpostgresql/pgwatch-demo:X.Y.Z\n</code></pre> <p>Note that in non-trusted environments it's a good idea to specify more sensitive ports together with some explicit network interfaces for additional security - by default Docker listens on all network devices!</p> <p>Also note that one can configure many aspects of the software components running inside the container via ENV - for a complete list of all supported Docker environment variables see the ENV_VARIABLES.md file.</p>"},{"location":"tutorial/docker_installation.html#available-docker-images","title":"Available Docker images","text":"<p>Following images are regularly pushed to Docker Hub:</p>"},{"location":"tutorial/docker_installation.html#cybertecpostgresqlpgwatch-demo","title":"cybertecpostgresql/pgwatch-demo","text":"<p>The original pgwatch \u201cbatteries-included\u201d image with PostgreSQL measurements storage. Just insert connect infos to your database via the admin Web UI (or directly into the Config DB) and then turn to the pre-defined Grafana dashboards to analyze DB health and performance.</p>"},{"location":"tutorial/docker_installation.html#cybertecpostgresqlpgwatch","title":"cybertecpostgresql/pgwatch","text":"<p>A light-weight image containing only the metrics collection daemon / agent, that can be integrated into the monitoring setup over configuration specified either via ENV, mounted YAML files or a PostgreSQL Config DB. See the Component reuse chapter for wiring details.</p>"},{"location":"tutorial/docker_installation.html#building-custom-docker-images","title":"Building custom Docker images","text":"<p>For custom tweaks, more security, specific component versions, etc. one could easily build the images themselves, just a Docker installation is needed.</p>"},{"location":"tutorial/docker_installation.html#interacting-with-the-docker-container","title":"Interacting with the Docker container","text":"<ul> <li> <p>If launched with the <code>PW_TESTDB=1</code> env. parameter then the     pgwatch configuration database running inside Docker is added to     the monitoring, so that you should immediately see some metrics at     least on the Health-check dashboard.</p> </li> <li> <p>To add new databases / instances to monitoring open the     administration Web interface on port 8080 (or some other port, if     re-mapped at launch) and go to the SOURCES page. Note that the Web UI     is an optional component, and one can manage monitoring entries     directly in the Postgres Config DB via <code>INSERT</code> / <code>UPDATE</code> into     <code>\"pgwatch.monitored_db\"</code> table. Default user/password are again     <code>pgwatch/pgwatchadmin</code>, database name - <code>pgwatch</code>. In both     cases note that it can take up to 2min (default main loop time,     changeable via <code>PW_SERVERS_REFRESH_LOOP_SECONDS</code>) before you see     any metrics for newly inserted databases.</p> </li> <li> <p>One can edit existing or create new Grafana dashboards, change     Grafana global settings, create users, alerts, etc. after logging in     as <code>pgwatch/pgwatchadmin</code> (by default, changeable at launch     time).</p> </li> <li> <p>Metrics and their intervals that are to be gathered can be     customized for every database separately via a custom JSON config     field or more conveniently by using Preset Configs, like     \"minimal\", \"basic\" or \"exhaustive\" (<code>monitored_db.preset_config</code>     table), where the name should already hint at the amount of metrics     gathered. For privileged users the \"exhaustive\" preset is a good     starting point, and \"unprivileged\" for simple developer accounts.</p> </li> <li> <p>To add a new metrics yourself (which are simple SQL queries     returning any values and a timestamp) head to     http://127.0.0.1:8080/metrics. The queries should always include a     <code>\"epoch_ns\"</code> column and <code>\"tag\\_\"</code> prefix can be used for columns     that should be quickly searchable/groupable, and thus will be     indexed with the PostgreSQL metric stores. See to the bottom of the     \"metrics\" page for more explanations or the documentation chapter     on metrics.</p> </li> <li> <p>For a quickstart on dashboarding, a list of available metrics     together with some instructions are presented on the     \"Documentation\" dashboard.</p> </li> <li> <p>Some built-in metrics like <code>\"cpu_load\"</code> and others, that gather     privileged or OS statistics, require installing helper functions     (looking like     that),     so it might be normal to see some blank panels or fetching errors in     the logs. On how to prepare databases for monitoring see the     Monitoring preparations chapter.</p> </li> <li> <p>For effective graphing you want to familiarize yourself with the     query language of the database system that was selected for metrics     storage. Some tips to get going:</p> </li> <li> <p>For PostgreSQL/TimescaleDB - some knowledge of Window         functions         is a must if looking at longer time periods of data as the         statistics could have been reset in the meantime by user         request or the server might have crashed, so that simple         <code>max() - min()</code> aggregates on cumulative counters (most data         provided by Postgres is cumulative) would lie.</p> </li> <li> <p>For possible troubleshooting needs, logs of the components running     inside Docker are by default (if not disabled on container launch)     visible under:     http://127.0.0.1:8080/logs/%5Bpgwatch%7Cpostgres%7Cwebui%7Cgrafana.     It's of course also possible to log into the container and look at     log files directly - they're situated under     <code>/var/logs/supervisor/</code>.</p> <p>FYI - <code>docker logs ...</code> command is not really useful after a successful container startup in pgwatch case.</p> </li> </ul>"},{"location":"tutorial/docker_installation.html#ports-used","title":"Ports used","text":"<ul> <li>5432 - Postgres configuration or metrics storage DB (when using the     cybertec/pgwatch image)</li> <li>8080 - Management Web UI (monitored hosts, metrics, metrics     configurations)</li> <li>3000 - Grafana dashboarding</li> </ul>"},{"location":"tutorial/docker_installation.html#docker-compose","title":"Docker Compose","text":"<p>As mentioned in the Components chapter, remember that the pre-built Docker images are just one example how your monitoring setup around the pgwatch metrics collector could be organized. For another example how various components (as Docker images here) can work together, see a Docker Compose example with loosely coupled components.</p>"},{"location":"tutorial/docker_installation.html#example-of-advanced-setup-using-yaml-files-and-dual-sinks","title":"Example of advanced setup using YAML files and dual sinks","text":"<p>pgwatch service in file <code>docker/docker-compose.yml</code> can look like this:</p> <pre><code>  pgwatch:\n    image: cybertecpostgresql/pgwatch:latest\n    command:\n      - \"--web-disable=true\"\n      - \"--sources=/sources.yaml\"\n      - \"--sink=postgresql://pgwatch@postgres:5432/pgwatch_metrics\"\n      - \"--sink=prometheus://:8080\"\n    volumes:\n      - \"./sources.yaml:/sources.yaml\"\n    ports:\n      - \"8080:8080\"\n    depends_on:\n      postgres:\n        condition: service_healthy\n</code></pre> <p>Source file <code>sources.yaml</code> in the same directory:</p> <pre><code>- name: demo\n  conn_str: postgresql://pgwatch:pgwatchadmin@postgres/pgwatch'\n  preset_metrics: exhaustive\n  is_enabled: true\n  group: default\n</code></pre> <p>Running this setup you get pgwatch that uses sources from YAML file and outputs measurements to postgres DB and exposes them for Prometheus to scrape on port 8080 instead of WebUI (which is disabled by <code>--web-disable</code>). Metrics definition are built-in, you can examine definition in <code>internal/metrics/metrics.yaml</code>.</p>"},{"location":"tutorial/preparing_databases.html","title":"Preparing databases for monitoring","text":""},{"location":"tutorial/preparing_databases.html#effects-of-monitoring","title":"Effects of monitoring","text":"<ul> <li>Although the \"Observer effect\" applies also for pgwatch, no     noticeable impact for the monitored DB is expected when using     Preset configs settings, and given that there is some normal load     on the server anyway and the DB doesn't have thousands of tables.     For some metrics though can happen that the metric reading query     (notably <code>stat_statements</code> and <code>table_stats</code>) takes some tens of     milliseconds, which might be more than an average application query.</li> <li>Default Postgres statement     timeout     is 5s for entries inserted via the Web UI / database directly.</li> </ul>"},{"location":"tutorial/preparing_databases.html#basic-preparations","title":"Basic preparations","text":"<p>As a base requirement you'll need a login user (<code>pg_monitor</code> suggested) for connecting to your server and fetching metrics.</p> <p>Though theoretically you can use any username you like, but if not using \"pgwatch\" you need to adjust the \"helper\" creation SQL scripts (see below for explanation) accordingly, as in those by default the \"pgwatch\" will be granted execute privileges.</p> <pre><code>CREATE ROLE pgwatch WITH LOGIN PASSWORD 'secret';\n-- For critical databases it might make sense to ensure that the user account\n-- used for monitoring can only open a limited number of connections\n-- (there are according checks in code, but multiple instances might be launched)\nALTER ROLE pgwatch CONNECTION LIMIT 5;\nGRANT pg_monitor TO pgwatch;\nGRANT CONNECT ON DATABASE mydb TO pgwatch;\nGRANT EXECUTE ON FUNCTION pg_stat_file(text) to pgwatch; -- for wal_size metric\nGRANT EXECUTE ON FUNCTION pg_stat_file(text, boolean) TO pgwatch;\n</code></pre> <p>For most monitored databases it's extremely beneficial (for troubleshooting performance issues) to also activate the pg_stat_statements extension which will give us exact \"per query\" performance aggregates and also enables to calculate how many queries are executed per second for example. In pgwatch context it powers the \"Stat statements Top\" dashboard and many other panels of other dashboards. For additional troubleshooting benefits also the track_io_timing setting should be enabled.</p> <ol> <li> <p>Make sure the Postgres contrib package is installed (should be     installed automatically together with the Postgres server package on     Debian based systems).</p> <ul> <li>On RedHat / Centos: <code>yum install -y postgresqlXY-contrib</code></li> <li>On Debian / Ubuntu: <code>apt install postgresql-contrib</code></li> </ul> </li> <li> <p>Add <code>pg_stat_statements</code> to your server config (postgresql.conf) and     restart the server.</p> <pre><code>shared_preload_libraries = 'pg_stat_statements'\ntrack_io_timing = on\n</code></pre> </li> <li> <p>After restarting activate the extension in the monitored DB. Assumes     Postgres superuser.</p> <pre><code>psql -c \"CREATE EXTENSION IF NOT EXISTS pg_stat_statements\"\n</code></pre> </li> </ol>"},{"location":"tutorial/preparing_databases.html#metrics-initialization","title":"Metrics initialization","text":"<p>Some rare metrics are not runable out-of-the-box on Postgres and need some installed helper functions, extensions or database objects before they can be used. For example, it is impossible to obtain the CPU usage statistics with a regular SQL query. But it is possible to get this system information with some untrusted procedure language like PL/Python.</p> <p>That's why some metrics have a special init section in their definitions. Some init sections might contain <code>CREATE FUNCTION</code> statements that create helper functions in the monitored database. Some might contain <code>CREATE EXTENSION</code> or other preparation steps.</p> <p>To examine the init section of a metric, you can use the following command:</p> <pre><code>pgwatch metric print-init &lt;metric or preset name&gt; ...\n</code></pre> <p>You may put multiple metric or preset names in the command line. The output will contain the concatenated init sections of the specified metrics or presets.</p> <p>For example, to check the init section of the <code>cpu_load</code> metric:</p> <pre><code>$ pgwatch metric print-init cpu_load\n--  cpu_load\nBEGIN;\nCREATE EXTENSION IF NOT EXISTS plpython3u;\nCREATE OR REPLACE FUNCTION get_load_average(OUT load_1min float, OUT load_5min float, OUT load_15min float) AS\n$$\n  from os import getloadavg\n  la = getloadavg()\n  return [la[0], la[1], la[2]]\n$$ LANGUAGE plpython3u VOLATILE;\nGRANT EXECUTE ON FUNCTION get_load_average() TO pgwatch;\nCOMMENT ON FUNCTION get_load_average() is 'created for pgwatch';\nCOMMIT;\n</code></pre> <p>Helper functions in pgwatch context are standard Postgres stored procedures, running under <code>SECURITY DEFINER</code> privileges. Via such wrapper functions one can do controlled privilege escalation, i.e. to give access to OS-level metrics.</p> <p>Since pgwatch operates with a \"least privilege\" principle, it shouldn't automatically create needed helper functions on the monitored database.</p> <p>So to create the helper functions, you need to execute init commands under the appropriate account, usually a superuser account. The easiest way to do it is just pipe the output of the <code>pgwatch metric print-init</code> command to the <code>psql</code> command:</p> <pre><code>export PGUSER=superuser\npgwatch metric print-init cpu_load psutil_mem psutil_disk | psql -d mydb\n</code></pre> <p>Info</p> <p>Here in all examples we assume that we are using the built-in metrics. But you can also use your own custom metrics. In this case, you need to provide the appropriate command-line options, e.g. <pre><code>pgwatch --metrics=/path/to/your/metrics.yaml metric print-init ...\n</code></pre></p> <p>Also when init metrics make sure the <code>search_path</code> is at defaults or set so that it's also accessible for the monitoring role as currently neither helpers nor metric definition SQLs don't assume any particular schema and depend on the <code>search_path</code> including everything needed.</p> <p>Hint</p> <p>If it can be foreseen that a lot of databases will be created on some instance it might be a good idea to roll out the helpers directly in the template1 database, so that all newly created databases will get them automatically.</p>"},{"location":"tutorial/preparing_databases.html#plpython-helpers","title":"PL/Python helpers","text":"<p>PostgreSQL in general is implemented in such a way that it does not know too much about the operating system that it is running on. This is a good thing for portability but can be somewhat limiting for monitoring, especially when there is no system monitoring framework in place or the data is not conveniently accessible together with metrics gathered from Postgres. To overcome this problem, users can also choose to install helpers extracting OS metrics like CPU, RAM usage, etc. so that this data is stored together with Postgres-native metrics for easier graphing / correlation / alerting. This also enable to be totally independent of any System Monitoring tools like Zabbix, etc., with the downside that everything is gathered over Postgres connections so that when Postgres is down no OS metrics can be gathered also.</p> <p>Note though that PL/Python is usually disabled by DB-as-a-service providers like AWS RDS for security reasons.</p> <pre><code># first install the Python bindings for Postgres\napt install postgresql-plpython3-XY\n# yum install postgresqlXY-plpython3\n\npgwatch metric print-init cpu_load | psql -d mydb\n\n# psutil helpers are only needed when full set of common OS metrics is wanted\napt install python3-psutil\npgwatch metric print-init psutil_cpu psutil_mem psutil_disk psutil_disk_io_total | psql -d mydb\n</code></pre>"},{"location":"tutorial/preparing_databases.html#notice-on-using-metric-fetching-helpers","title":"Notice on using metric fetching helpers","text":"<ul> <li>Helpers are mostly needed only for PL/Python metrics getting OS statistics.</li> <li>For gathering OS statistics (CPU, IO, disk) there are helpers and     metrics provided, based on the \"psutil\" Python package... but from     user reports seems the package behaviour differentiates slightly     based on the Linux distro / Kernel version used, so small     adjustments might be needed there (e.g. to remove a non-existent     column). Minimum usable Kernel version required is 3.3.</li> <li>When running the gatherer locally one can enable the <code>--direct-os-stats</code>      parameter to signal that we can fetch the data for the default <code>psutil*</code> metrics     directly from OS counters. If direct OS fetching fails though, the     fallback is still to try via PL/Python wrappers.</li> <li>In rare cases when some \"helpers\" have been installed, and when     doing a binary PostgreSQL upgrade at some later point in time via     <code>pg_upgrade</code>, this could result in error messages     thrown. Then just drop those failing helpers on the \"to be     upgraded\" cluster and re-create them after the upgrade process.</li> </ul> <p>Info</p> <p>If despite all the warnings you still want to run the pgwatch with a sufficient user account (e.g. a superuser) you can also use the <code>--create-helpers</code> parameter to automatically create all needed helper functions in the monitored databases.</p>"},{"location":"tutorial/preparing_databases.html#running-with-developer-credentials","title":"Running with developer credentials","text":"<p>For developers with no means to install any wrappers as superuser, it's also possible to benefit from pgwatch. For such use cases the \"unprivileged\" preset metrics profile and the according \"DB overview Unprivileged / Developer\"  are a good starting point as it only assumes existence of <code>pg_stat_statements</code> (which should be available by all cloud providers).</p>"},{"location":"tutorial/preparing_databases.html#different-source-types-explained","title":"Different source types explained","text":"<p>When adding a new \"to be monitored\" entry a source type needs to be selected. Following types are available:</p>"},{"location":"tutorial/preparing_databases.html#postgres","title":"postgres","text":"<p>Monitor a single database on a single Postgres instance. Internally monitoring  always happens \"per DB\" not \"per cluster\" though.</p>"},{"location":"tutorial/preparing_databases.html#postgres-continuous-discovery","title":"postgres-continuous-discovery","text":"<p>Monitor a whole (or subset of DB-s) of Postgres cluster / instance. Connection string needs to be specified and then the pgwatch daemon will periodically scan the cluster and add any found and not yet monitored DBs to monitoring. In this mode it's also possible to specify regular expressions to include/exclude some database names.</p>"},{"location":"tutorial/preparing_databases.html#pgbouncer","title":"pgbouncer","text":"<p>Use to track metrics from PgBouncer's <code>SHOW STATS</code> command.</p>"},{"location":"tutorial/preparing_databases.html#pgpool","title":"pgpool","text":"<p>Use to track joint metrics from Pgpool2's <code>SHOW POOL_NODES</code> and <code>SHOW POOL_PROCESSES</code> commands.</p>"},{"location":"tutorial/preparing_databases.html#patroni","title":"patroni","text":"<p>Patroni is a HA / cluster manager for Postgres that relies on a DCS (Distributed Consensus Store) to store it's state. Typically, in such a setup the nodes come and go, and also it should not matter who is currently the master. To make it easier to monitor such dynamic constellations pgwatch supports reading of cluster node info from all supported DCSs (etcd, Zookeeper, Consul), but currently only for simpler cases with no security applied (which is actually the common case in a trusted environment).</p> <p>Connection string should point to the DCS, and then pgwatch will periodically scan the DCS and add any found and not yet monitored. If you use etcd as the DCS, then your connection string should look like this: <code>etcd://host:port[,host:port..]/namespace/scope</code>, for example <code>etcd://localhost:2379/service/batman</code>.</p> <p>You may omit the scope part to resolve all databases in the specified namespace, or you may specify the scope to resolve only databases from the specific Patroni cluster.</p> <p>Notice</p> <p>All \"continuous\" modes expect access to \"template1\" or \"postgres\" databases of the specified cluster to determine the database names residing there.</p>"},{"location":"tutorial/upgrading.html","title":"Upgrading","text":"<p>The pgwatch daemon code doesn't need too much maintenance itself (if you're not interested in new features), but the preset metrics, dashboards and the other components that pgwatch relies on, like Grafana, are under very active development and get updates quite regularly so already purely from the security standpoint it would make sense to stay up to date.</p> <p>We also regularly include new component versions in the Docker images after verifying that they work. If using Docker, you could also choose to build your own images any time some new component versions are released, just increment the version numbers in the Dockerfile.</p>"},{"location":"tutorial/upgrading.html#updating-to-a-newer-docker-version","title":"Updating to a newer Docker version","text":""},{"location":"tutorial/upgrading.html#without-volumes","title":"Without volumes","text":"<p>If pgwatch container was started in the simplest way possible without volumes, and if previously gathered metrics are not of great importance, and there are no user modified metric or dashboard changes that should be preserved, then the easiest way to get the latest components would be just to launch new container and import the old monitoring config:</p> <pre><code># let's backup up the monitored hosts\npsql -p5432 -U pgwatch -d pgwatch -c \"\\copy monitored_db to 'monitored_db.copy'\"\n\n# stop the old container and start a new one ...\ndocker stop ... &amp;&amp; docker run ....\n\n# import the monitored hosts\npsql -p5432 -U pgwatch -d pgwatch -c \"\\copy monitored_db from 'monitored_db.copy'\"\n</code></pre> <p>If metrics data and other settings like custom dashboards need to be preserved then some more steps are needed, but basically it's about pulling Postgres backups and restoring them into the new container.</p> <p>A tip: to make the restore process easier it would already make sense to mount the host folder with the backups in it on the new container with <code>\"-v \\~/pgwatch_backups:/pgwatch_backups:rw,z\"</code> when starting the Docker image. Otherwise, one needs to set up SSH or use something like S3 for example. Also note that port 5432 need to be exposed to take backups outside of Docker for Postgres respectively.</p>"},{"location":"tutorial/upgrading.html#with-volumes","title":"With volumes","text":"<p>To make updates a bit easier, the preferred way to launch pgwatch should be to use Docker volumes for each individual component - see the Installing using Docker chapter for details. Then one can just stop the old container and start a new one, re-using the volumes.</p> <p>With some releases though, updating to newer version might additionally still require manual rollout of Config DB schema migrations scripts, so always check the release notes for hints on that or just go to the <code>\"pgwatch/sql/migrations\"</code> folder and execute all SQL scripts that have a higher version than the old pgwatch container. Error messages like will \"missing columns\" or \"wrong datatype\" will also hint at that, after launching with a new image. FYI - such SQL \"patches\" are generally not provided for metric updates, nor dashboard changes, and they need to be updated separately.</p>"},{"location":"tutorial/upgrading.html#updating-without-docker","title":"Updating without Docker","text":"<p>For a custom installation there's quite some freedom in doing updates - as components (Grafana, PostgreSQL) are loosely coupled, they can be updated any time without worrying too much about the other components. Only \"tightly coupled\" components are the pgwatch metrics collector, config DB and the optional Web UI - if the pgwatch config is kept in the database. If YAML based approach is used, then things are even more simple - the pgwatch daemon can be updated any time as YAML schema has default values for everything and there are no other \"tightly coupled\" components like the Web UI.</p>"},{"location":"tutorial/upgrading.html#updating-grafana","title":"Updating Grafana","text":"<p>The update process for Grafana looks pretty much like the installation so take a look at the according chapter. If using Grafana package repository it should happen automatically along with other system packages. Grafana has a built-in database schema migrator, so updating the binaries and restarting is enough.</p>"},{"location":"tutorial/upgrading.html#updating-grafana-dashboards","title":"Updating Grafana dashboards","text":"<p>There are no update or migration scripts for the built-in Grafana dashboards as it would break possible user applied changes. If you know that there are no user changes, then one can just delete or rename the existing ones in bulk and import the latest JSON definitions. See here for some more advice on how to manage dashboards.</p>"},{"location":"tutorial/upgrading.html#updating-the-config-metrics-db-version","title":"Updating the config / metrics DB version","text":"<p>Database updates can be quite complex, with many steps, so it makes sense to follow the manufacturer's instructions here.</p> <p>For PostgreSQL one should distinguish between minor version updates and major version upgrades. Minor updates are quite straightforward and problem-free, consisting of running something like:</p> <pre><code>apt update &amp;&amp; apt install postgresql\nsudo systemctl restart postgresql\n</code></pre> <p>For PostgreSQL major version upgrades one should read through the according release notes (e.g. here) and be prepared for the unavoidable downtime.</p>"},{"location":"tutorial/upgrading.html#updating-the-pgwatch-schema","title":"Updating the pgwatch schema","text":"<p>This is the pgwatch specific part, with some coupling between the following components - Configuration DB SQL schema and pgwatch binary.</p> <p>First of all, the pgwatch binary needs to be updated to a newer version. Then try to run the pgwatch as usual:</p> <pre><code>pgwatch --sources=postgresql://pgwatch:pgwatchadmin@localhost/pgwatch --sink=postgresql://pgwatch:pgwatchadmin@localhost/pgwatch_metrics\n\n[ERROR] configuration needs upgrade, use \"config upgrade\" command\nexit status 4\n</code></pre> <p>If you see the above error message, then the pgwatch schema needs updating. This is done by running the following command, which will apply all the necessary SQL migrations to the configuration database:</p> <pre><code>pgwatch --sources=postgresql://pgwatch:pgwatchadmin@localhost/pgwatch config upgrade\n\n[INFO] Applying migration named '00824 Refactor recommendations'...\n[INFO] Applied migration named '00824 Refactor recommendations'\n</code></pre>"},{"location":"tutorial/upgrading.html#updating-the-metrics-collector","title":"Updating the metrics collector","text":"<p>Compile or install the gatherer from RPM / DEB / tarball packages. See the Custom installation  chapter for details.</p> <p>If using a SystemD service file to auto-start the collector then you might want to also check for possible updates on the template there - <code>/etc/pgwatch/startup-scripts/pgwatch.service</code>.</p>"},{"location":"tutorial/upgrading.html#updating-metric-definitions","title":"Updating metric definitions","text":"<p>In the YAML mode you always get new SQL definitions for the built-in metrics automatically when refreshing the sources via GitHub or pre-built packages, but with Config DB approach one needs to do it manually. Given that there are no user added metrics, it's simple enough though - just delete all old ones and re-insert everything from the latest metric definition SQL file.</p> <pre><code>pg_dump -t pgwatch.metric pgwatch &gt; old_metric.sql  # a just-in-case backup\npsql  -c \"truncate pgwatch.metric\" pgwatch\npsql -f /etc/pgwatch/sql/config_store/metric_definitions.sql pgwatch\n</code></pre> <p>Warning</p> <p>If you have added some own custom metrics be sure not to delete or truncate them!</p>"}]}